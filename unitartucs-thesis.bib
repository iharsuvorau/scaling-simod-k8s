@article{camargo_simod_nodate,
	title = {Simod: A Tool for Automated Discovery of Business Process Simulation Models},
	abstract = {Business process simulation is a widespread approach for quantitative analysis of business processes. However, the creation of accurate business process simulation models is a laborious and error-prone task, due to the numerous parameters that need to be carefully tuned. Additionally, the accuracy of a simulation model is inherently limited by the accuracy of the process model that is used as a starting point. This paper presents Simod: A tool to automatically generate simulation models from event logs. Simod uses an automated process discovery technique to extract a process model from an event log and then enhances this model with simulation parameters extracted via a combination of trace alignment, replay, and curve-ﬁtting techniques. The tool incorporates a Bayesian hyperparameter optimization technique to ﬁne-tune the accuracy of the resulting simulation model.},
	pages = {5},
	author = {Camargo, Manuel and Dumas, Marlon and Gonzalez-Rojas, Oscar},
	langid = {english},
	file = {Camargo et al. - Simod A Tool for Automated Discovery of Business .pdf:/Users/ihar/Documents/Zotero/storage/C5KDAZK4/Camargo et al. - Simod A Tool for Automated Discovery of Business .pdf:application/pdf},
}

@article{slaats_declarative_2020,
	title = {Declarative and Hybrid Process Discovery: Recent Advances and Open Challenges},
	volume = {9},
	issn = {1861-2032, 1861-2040},
	url = {http://link.springer.com/10.1007/s13740-020-00112-9},
	doi = {10.1007/s13740-020-00112-9},
	shorttitle = {Declarative and Hybrid Process Discovery},
	abstract = {Knowledge-intensive processes, such as those encountered in health care, ﬁnance and government, tend to allow a large degree of ﬂexibility: there are many possible solutions towards a goal, and it is left to the expertise of knowledge workers to ﬁnd the one most suitable for the particular case at hand. As a result, such processes usually exhibit more varied behaviour than traditional production processes. This poses a challenge for process discovery algorithms that return imperative, ﬂow-based, models. The models tend to become highly complex when representing many alternative paths, and therefore, the miners need to either sacriﬁce on simplicity, ﬁtness, or precision. It has been proposed that one should discover the constraints of the process instead, based on the assumption that such a constraint-based, declarative process model can describe highly varied behaviour more concisely. More recently, it has been observed that many processes do not neatly fall in one category or the other; instead, they contain both ﬂexible and rigid parts. In such cases, it may be helpful to identify these parts and mine constraints for some and ﬂow for others, resulting in a hybrid model. In this paper, we provide an overview of recent advances in both declarative and hybrid process discovery, discuss a number of open challenges that still remain, and propose directions for future research.},
	pages = {3--20},
	number = {1},
	journaltitle = {Journal on Data Semantics},
	shortjournal = {J Data Semant},
	author = {Slaats, Tijs},
	urldate = {2022-04-09},
	date = {2020-03},
	langid = {english},
	file = {Slaats - 2020 - Declarative and Hybrid Process Discovery Recent A.pdf:/Users/ihar/Documents/Zotero/storage/Y47RJ5JC/Slaats - 2020 - Declarative and Hybrid Process Discovery Recent A.pdf:application/pdf},
}

@incollection{felderer_design_2020,
	location = {Cham},
	title = {The Design Science Paradigm as a Frame for Empirical Software Engineering},
	isbn = {978-3-030-32488-9 978-3-030-32489-6},
	url = {http://link.springer.com/10.1007/978-3-030-32489-6_5},
	abstract = {Software engineering research aims to help improve real-world practice. With the adoption of empirical software engineering research methods, the understanding of real-world needs and validation of solution proposals have evolved. However, the philosophical perspective on what constitutes theoretical knowledge and research contributions in software engineering is less discussed in the community. In this chapter, we use the design science paradigm as a frame for articulating and communicating prescriptive software engineering research contributions. Design science embraces problem conceptualization, solution (or artifact) design, and validation of solution proposals, with recommendations for practice phrased as technological rules. Design science is used in related research areas, particularly information systems and management theory. We elaborate the constructs of design science for software engineering, relate them to diﬀerent conceptualizations of design science and provide examples of possible research methods. We outline how the assessment of research contributions, industry-academia communication and theoretical knowledge building may be supported by the design science paradigm. Finally, we provide examples of software engineering research presented through a design science lens.},
	pages = {127--147},
	booktitle = {Contemporary Empirical Methods in Software Engineering},
	publisher = {Springer International Publishing},
	author = {Runeson, Per and Engström, Emelie and Storey, Margaret-Anne},
	editor = {Felderer, Michael and Travassos, Guilherme Horta},
	urldate = {2022-10-05},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-32489-6_5},
	file = {Runeson et al. - 2020 - The Design Science Paradigm as a Frame for Empiric.pdf:/Users/ihar/Documents/Zotero/storage/R2C8KL4N/Runeson et al. - 2020 - The Design Science Paradigm as a Frame for Empiric.pdf:application/pdf},
}

@inproceedings{cartaxo_evidence_2016,
	location = {Ciudad Real Spain},
	title = {Evidence Briefings: Towards a Medium to Transfer Knowledge from Systematic Reviews to Practitioners},
	isbn = {978-1-4503-4427-2},
	url = {https://dl.acm.org/doi/10.1145/2961111.2962603},
	doi = {10.1145/2961111.2962603},
	shorttitle = {Evidence Briefings},
	abstract = {Method: We selected a set of systematic reviews identiﬁed by a tertiary study and extracted their ﬁndings to generate one-page Evidence Brieﬁngs to serve as mediums. A design specialist deﬁned the brieﬁngs structure based on information design and gestalt principles. To evaluate the format and content of the brieﬁngs we conducted personal opinion surveys based on two groups: {StackExchange} users that posted questions in topics related to the reviews, and the authors of the selected reviews themselves. The former had a response rate of 21.9\% (32 out 146) and the latter 31.8\% (7 out of 22).
Results: Practitioners rarely use systematic review research papers as mediums to acquire knowledge, since just 9\% have told to do so. Both researchers and practitioners positively evaluated the evidence brieﬁngs, since 71\% and 82\% of the {StackExchange} users and systematic review authors, respectively, agreed or strongly agreed that the brieﬁngs’ interface is clear.
Conclusions: Researchers and practitioners were positive about the content and format of the evidence brieﬁngs we proposed. It is also possible to say that there is a gap between practitioners and systematic reviews due to the low percentage of practitioners that consume systematic reviews. The good reception of the evidence brieﬁngs from both sides show a possible route to reduce that gap.},
	eventtitle = {{ESEM} '16: {ACM}/{IEEE} 9th International Symposium on Empirical Software Engineering and Measurement},
	pages = {1--10},
	booktitle = {Proceedings of the 10th {ACM}/{IEEE} International Symposium on Empirical Software Engineering and Measurement},
	publisher = {{ACM}},
	author = {Cartaxo, Bruno and Pinto, Gustavo and Vieira, Elton and Soares, Sérgio},
	urldate = {2022-10-05},
	date = {2016-09-08},
	langid = {english},
	file = {Cartaxo et al. - 2016 - Evidence Briefings Towards a Medium to Transfer K.pdf:/Users/ihar/Documents/Zotero/storage/FIE4NBYN/Cartaxo et al. - 2016 - Evidence Briefings Towards a Medium to Transfer K.pdf:application/pdf},
}

@article{hill_what_1990,
	title = {What is scalability?},
	volume = {18},
	issn = {0163-5964},
	url = {https://dl.acm.org/doi/10.1145/121973.121975},
	doi = {10.1145/121973.121975},
	abstract = {Scalability
              is a frequently-claimed attribute of multiprocessor systems. While the basic notion is intuitive, scalability has no generally-accepted definition. For this reason, current use of the term adds more to marketing potential than technical insight.In this paper, I first examine formal definitions of scalability, but
              I fail to lind a useful, rigorous definition of it
              . I then question whether scalability is useful and conclude by challenging the technical community to either (1) rigorously define scalability or (2) stop using it to describe systems.},
	pages = {18--21},
	number = {4},
	journaltitle = {{ACM} {SIGARCH} Computer Architecture News},
	shortjournal = {{SIGARCH} Comput. Archit. News},
	author = {Hill, Mark D.},
	urldate = {2022-10-15},
	date = {1990-12-02},
	langid = {english},
	file = {Hill - 1990 - What is scalability.pdf:/Users/ihar/Documents/Zotero/storage/KK7RM2RB/Hill - 1990 - What is scalability.pdf:application/pdf},
}

@article{haoues_guideline_2017,
	title = {A guideline for software architecture selection based on {ISO} 25010 quality related characteristics},
	volume = {8},
	issn = {0975-6809, 0976-4348},
	url = {http://link.springer.com/10.1007/s13198-016-0546-8},
	doi = {10.1007/s13198-016-0546-8},
	abstract = {As the complexity of software increases, the choice of the appropriate software architecture becomes a critical task. This paper provides a guideline for selecting the appropriate software architecture based on pertinent {ISO} 25010 quality characteristics. The guideline was established through an analytical survey of 113 papers published from 2010 to 2014. Through this survey, we ﬁrst identiﬁed a set of commonly used software architectures in the software engineering literature. Secondly, we applied the Formal Concept Analysis technique to classify each one of these architectures according to {ISO} 25010 quality characteristics. Finally, we identiﬁed the relationships among {ISO} 25010 quality characteristics, which in turn helped us to develop a guideline on how to select the appropriate software architecture with respect to {ISO} 25010 quality characteristics. In order to make sure about the validation of the proposed guideline, a survey with industrial experts is in progress. Data were collected from two companies working in the software development ﬁeld ({ST}2i and Telnet).},
	pages = {886--909},
	issue = {S2},
	journaltitle = {International Journal of System Assurance Engineering and Management},
	shortjournal = {Int J Syst Assur Eng Manag},
	author = {Haoues, Mariem and Sellami, Asma and Ben-Abdallah, Hanêne and Cheikhi, Laila},
	urldate = {2022-10-15},
	date = {2017-11},
	langid = {english},
	file = {Haoues et al. - 2017 - A guideline for software architecture selection ba.pdf:/Users/ihar/Documents/Zotero/storage/NDUQKPSH/Haoues et al. - 2017 - A guideline for software architecture selection ba.pdf:application/pdf},
}

@inproceedings{duboc_framework_2007,
	location = {Dubrovnik, Croatia},
	title = {A framework for characterization and analysis of software system scalability},
	isbn = {978-1-59593-811-4},
	url = {http://portal.acm.org/citation.cfm?doid=1287624.1287679},
	doi = {10.1145/1287624.1287679},
	abstract = {The term scalability appears frequently in computing literature, but it is a term that is poorly deﬁned and poorly understood. The lack of a clear, consistent and systematic treatment of scalability makes it diﬃcult to evaluate claims of scalability and to compare claims from diﬀerent sources. This paper presents a framework for precisely characterizing and analyzing the scalability of a software system. The framework treats scalability as a multi-criteria optimization problem and captures the dependency relationships that underlie typical notions of scalability. The paper presents the results of a case study in which the framework and analysis method were applied to a real-world system, demonstrating that it is possible to develop a precise, systematic characterization of scalability and to use the characterization to compare the scalability of alternative system designs.},
	eventtitle = {the the 6th joint meeting of the European software engineering conference and the {ACM} {SIGSOFT} symposium},
	pages = {375},
	booktitle = {Proceedings of the the 6th joint meeting of the European software engineering conference and the {ACM} {SIGSOFT} symposium on The foundations of software engineering  - {ESEC}-{FSE} '07},
	publisher = {{ACM} Press},
	author = {Duboc, Leticia and Rosenblum, David and Wicks, Tony},
	urldate = {2022-10-15},
	date = {2007},
	langid = {english},
	file = {Duboc et al. - 2007 - A framework for characterization and analysis of s.pdf:/Users/ihar/Documents/Zotero/storage/UE99QZLP/Duboc et al. - 2007 - A framework for characterization and analysis of s.pdf:application/pdf},
}

@book{sommerville_software_2011,
	location = {Boston},
	edition = {9th ed},
	title = {Software engineering},
	isbn = {978-0-13-703515-1 978-0-13-705346-9},
	pagetotal = {773},
	publisher = {Pearson},
	author = {Sommerville, Ian},
	date = {2011},
	langid = {english},
	note = {{OCLC}: ocn462909026},
	keywords = {Software engineering},
	file = {Sommerville - 2011 - Software engineering.pdf:/Users/ihar/Documents/Zotero/storage/Y7UBTJB9/Sommerville - 2011 - Software engineering.pdf:application/pdf},
}

@inproceedings{duboc_framework_2006,
	location = {Shanghai China},
	title = {A framework for modelling and analysis of software systems scalability},
	isbn = {978-1-59593-375-1},
	url = {https://dl.acm.org/doi/10.1145/1134285.1134460},
	doi = {10.1145/1134285.1134460},
	abstract = {Scalability is a widely-used term in scientiﬁc papers, technical magazines and software descriptions. Its use in the most varied contexts contribute to a general confusion about what the term really means. This lack of consensus is a potential source of problems, as assumptions are made in the face of a scalability claim. A clearer and widely-accepted understanding of scalability is required to restore the usefulness of the term. This research investigates commonly found definitions of scalability and attempts to capture its essence in a systematic framework. Its expected contribution is in assisting software developers to reason, characterize, communicate and adjust the scalability of software systems.},
	eventtitle = {{ICSE}06: International Conference on Software Engineering},
	pages = {949--952},
	booktitle = {Proceedings of the 28th international conference on Software engineering},
	publisher = {{ACM}},
	author = {Duboc, Leticia and Rosenblum, David S. and Wicks, Tony},
	urldate = {2022-10-15},
	date = {2006-05-28},
	langid = {english},
	file = {Duboc et al. - 2006 - A framework for modelling and analysis of software.pdf:/Users/ihar/Documents/Zotero/storage/FMX2M7EB/Duboc et al. - 2006 - A framework for modelling and analysis of software.pdf:application/pdf},
}

@article{brataas_idi_nodate,
	title = {{IDI}, {NTNU} Trondheim, Norway},
	abstract = {We describe a structured, hierarchic approach to exploring the scalability of {IT} systems architectures. An architecture is considered to be scalable over a particular set of requirements if the physical resource usage per unit of capacity remains roughly constant. For completeness, both requirements and capacity must be defined in the three dimensions of processing, storage and connectivity. Interactions between the three dimensions are considered, as are various forms of departure from non-uniform scaling. Scalability is explored via a combination of measurement and static and dynamic models. Appropriate scale-invariants are introduced to eliminate congestion effects and packaging issues from the analysis. This paper focuses on processing and to a lesser extent, on storage. The method is applied to a practical case study of Transigo, a J2EE-based software platform used in the Norwegian banking industry. We find that understanding the relationship between replication and upgrade for systems, subsystems and devices is key to guiding the exploration of scalability.},
	pages = {5},
	author = {Brataas, Gunnar},
	langid = {english},
	file = {Brataas - IDI, NTNU Trondheim, Norway.pdf:/Users/ihar/Documents/Zotero/storage/YQD38JVX/Brataas - IDI, NTNU Trondheim, Norway.pdf:application/pdf},
}

@article{jogalekar_evaluating_2000,
	title = {Evaluating the scalability of distributed systems},
	volume = {11},
	issn = {10459219},
	url = {http://ieeexplore.ieee.org/document/862209/},
	doi = {10.1109/71.862209},
	abstract = {ÐMany distributed systems must be scalable, meaning that they must be economically deployable in a wide range of sizes and configurations. This paper presents a scalability metric based on cost-effectiveness, where the effectiveness is a function of the system's throughput and its quality of service. It is part of a framework which also includes a scaling strategy for introducing changes as a function of a scale factor, and an automated virtual design optimization at each scale factor. This is an adaptation of concepts for scalability measures in parallel computing. Scalability is measured by the range of scale factors that give a satisfactory value of the metric, and good scalability is a joint property of the initial design and the scaling strategy. The results give insight into the scaling capacity of the designs, and into how to improve the design. A rapid simple bound on the metric is also described. The metric is demonstrated in this work by applying it to some well-known idealized systems, and to real prototypes of communications software.},
	pages = {589--603},
	number = {6},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	shortjournal = {{IEEE} Trans. Parallel Distrib. Syst.},
	author = {Jogalekar, P. and Woodside, M.},
	urldate = {2022-10-15},
	date = {2000-06},
	langid = {english},
	file = {Jogalekar and Woodside - 2000 - Evaluating the scalability of distributed systems.pdf:/Users/ihar/Documents/Zotero/storage/JLGTE2W9/Jogalekar and Woodside - 2000 - Evaluating the scalability of distributed systems.pdf:application/pdf},
}

@inproceedings{gorton_foundations_2022,
	location = {Honolulu, {HI}, {USA}},
	title = {Foundations of Scalable Software Architectures},
	isbn = {978-1-66549-493-9},
	url = {https://ieeexplore.ieee.org/document/9779797/},
	doi = {10.1109/ICSA-C54293.2022.00052},
	abstract = {Scalability is a driving software quality attribute for many contemporary, Internet-facing systems. Applications that fail or perform slowly and reject requests under high request loads are rapidly deserted by users, and the resulting business and societal impacts can be profound. This paper summarizes some of the key foundational issues of scalable software and system architectures. Design patterns and tactics needed to ensure scalability are briefly described for both the processing and persistence layers. A case study of a novel approach to balance performance and cost is also presented and we show how this approach can be applied to cloud-based scalable architectures. Detailed coverage of these issues was presented in a tutorial at {ICSA} 2022.},
	eventtitle = {2022 {IEEE} 19th International Conference on Software Architecture Companion ({ICSA}-C)},
	pages = {233--236},
	booktitle = {2022 {IEEE} 19th International Conference on Software Architecture Companion ({ICSA}-C)},
	publisher = {{IEEE}},
	author = {Gorton, Ian and Teja Rayavarapu, Vijaya},
	urldate = {2022-10-15},
	date = {2022-03},
	langid = {english},
	file = {Gorton and Teja Rayavarapu - 2022 - Foundations of Scalable Software Architectures.pdf:/Users/ihar/Documents/Zotero/storage/C6UKHQWI/Gorton and Teja Rayavarapu - 2022 - Foundations of Scalable Software Architectures.pdf:application/pdf},
}

@book{douglass_real-time_2003,
	location = {Boston, {MA}},
	title = {Real-Time Design Patterns: robust scalable architecture for Real-time systems},
	isbn = {978-0-201-69956-2},
	series = {The Addison-Wesley object technology series},
	shorttitle = {Real-Time Design Patterns},
	pagetotal = {500},
	publisher = {Addison-Wesley},
	author = {Douglass, Bruce Powel},
	date = {2003},
	langid = {english},
	keywords = {Computer architecture, Real-time data processing, Software patterns},
	file = {Douglass - 2003 - Real-Time Design Patterns robust scalable archite.pdf:/Users/ihar/Documents/Zotero/storage/6JFPXEHR/Douglass - 2003 - Real-Time Design Patterns robust scalable archite.pdf:application/pdf},
}

@article{camargo_automated_2020,
	title = {Automated discovery of business process simulation models from event logs},
	volume = {134},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923620300397},
	doi = {10.1016/j.dss.2020.113284},
	abstract = {Business process simulation is a versatile technique to estimate the performance of a process under multiple scenarios. This, in turn, allows analysts to compare alternative options to improve a business process. A common roadblock for business process simulation is that constructing accurate simulation models is cumbersome and error-prone. Modern information systems store detailed execution logs of the business processes they support. Previous work has shown that these logs can be used to discover simulation models. However, existing methods for log-based discovery of simulation models do not seek to optimize the accuracy of the resulting models. Instead they leave it to the user to manually tune the simulation model to achieve the desired level of accuracy. This article presents an accuracy-optimized method to discover business process simulation models from execution logs. The method decomposes the problem into a series of steps with associated configuration parameters. A hyper-parameter optimization method is used to search through the space of possible configurations so as to maximize the similarity between the behavior of the simulation model and the behavior observed in the log. The method has been implemented as a tool and evaluated using logs from different domains.},
	pages = {113284},
	journaltitle = {Decision Support Systems},
	shortjournal = {Decision Support Systems},
	author = {Camargo, Manuel and Dumas, Marlon and González-Rojas, Oscar},
	urldate = {2022-10-16},
	date = {2020-07},
	langid = {english},
	file = {Camargo et al. - 2020 - Automated discovery of business process simulation.pdf:/Users/ihar/Documents/Zotero/storage/WG24629N/Camargo et al. - 2020 - Automated discovery of business process simulation.pdf:application/pdf},
}

@article{augusto_split_2019,
	title = {Split miner: automated discovery of accurate and simple business process models from event logs},
	volume = {59},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com/10.1007/s10115-018-1214-x},
	doi = {10.1007/s10115-018-1214-x},
	shorttitle = {Split miner},
	abstract = {The problem of automated discovery of process models from event logs has been intensively researched in the past two decades. Despite a rich ﬁeld of proposals, state-of-theart automated process discovery methods suffer from two recurrent deﬁciencies when applied to real-life logs: (i) they produce large and spaghetti-like models; and (ii) they produce models that either poorly ﬁt the event log (low ﬁtness) or over-generalize it (low precision). Striking a trade-off between these quality dimensions in a robust and scalable manner has proved elusive. This paper presents an automated process discovery method, namely Split Miner, which produces simple process models with low branching complexity and consistently high and balanced ﬁtness and precision, while achieving considerably faster execution times than state-of-the-art methods, measured on a benchmark covering twelve real-life event logs. Split Miner combines a novel approach to ﬁlter the directly-follows graph induced by an event log, with an approach to identify combinations of split gateways that accurately capture the concurrency, conﬂict and causal relations between neighbors in the directly-follows graph. Split Miner is also the ﬁrst automated process discovery method that is guaranteed to produce deadlock-free process models with concurrency, while not being restricted to producing block-structured process models.},
	pages = {251--284},
	number = {2},
	journaltitle = {Knowledge and Information Systems},
	shortjournal = {Knowl Inf Syst},
	author = {Augusto, Adriano and Conforti, Raffaele and Dumas, Marlon and La Rosa, Marcello and Polyvyanyy, Artem},
	urldate = {2022-10-16},
	date = {2019-05},
	langid = {english},
	file = {Augusto et al. - 2019 - Split miner automated discovery of accurate and s.pdf:/Users/ihar/Documents/Zotero/storage/Z2GYDHL2/Augusto et al. - 2019 - Split miner automated discovery of accurate and s.pdf:application/pdf},
}

@software{camargo_simod_2021,
	title = {Simod: Automated discovery of {BPS} models. Source code at {GitHub}},
	rights = {Apache-2.0 license},
	url = {https://github.com/AutomatedProcessImprovement/simod/tree/v2.3.1},
	shorttitle = {Simod},
	version = {v2.3.1},
	author = {Camargo, Manuel},
	urldate = {2022-10-16},
	date = {2021-03-24},
}

@online{abel_madis_qbp_2020,
	title = {{QBP} Simulator: Business Process Simulator for {BPMN}},
	url = {https://www.qbp-simulator.com},
	shorttitle = {{QBP} Simulator},
	titleaddon = {{QBP} Simulator: Business Process Simulator for {BPMN}},
	author = {Abel, Madis},
	urldate = {2022-10-16},
	date = {2020},
}

@book{bourque_guide_2014,
	title = {Guide to the Software Engineering Body of Knowledge, Version 3.0},
	url = {https://www.computer.org/education/bodies-of-knowledge/software-engineering},
	publisher = {{IEEE} Computer Society},
	author = {Bourque, P. and Fairley, R.E.},
	urldate = {2022-10-16},
	date = {2014},
}

@inproceedings{tumay_business_1995,
	location = {Arlington, {VA}, {USA}},
	title = {Business process simulation},
	isbn = {978-0-7803-3018-4},
	url = {http://ieeexplore.ieee.org/document/478705/},
	doi = {10.1109/WSC.1995.478705},
	abstract = {This introductory tutorial provides an overview of business process simulation, describes the modeling and analysis considerations, and lists typical model input, simulation and output requirements. A classification of simulation software products is provided to aid the user in understanding the business process simulation tools. Finally, a simulation exercise is presented to illustrate the power and suitability of simulation for analyzing a business process.},
	eventtitle = {1995 Winter Simulation Conference},
	pages = {55--60},
	booktitle = {Winter Simulation Conference Proceedings, 1995.},
	publisher = {{IEEE}},
	author = {Tumay, K.},
	urldate = {2022-11-15},
	date = {1995},
	langid = {english},
	file = {Tumay - 1995 - Business process simulation.pdf:/Users/ihar/Documents/Zotero/storage/5K37FQVJ/Tumay - 1995 - Business process simulation.pdf:application/pdf},
}

@article{augusto_automated_2019,
	title = {Automated Discovery of Process Models from Event Logs: Review and Benchmark},
	volume = {31},
	issn = {1041-4347, 1558-2191, 2326-3865},
	url = {https://ieeexplore.ieee.org/document/8368306/},
	doi = {10.1109/TKDE.2018.2841877},
	shorttitle = {Automated Discovery of Process Models from Event Logs},
	abstract = {Process mining allows analysts to exploit logs of historical executions of business processes to extract insights regarding the actual performance of these processes. One of the most widely studied process mining operations is automated process discovery. An automated process discovery method takes as input an event log, and produces as output a business process model that captures the control-ﬂow relations between tasks that are observed in or implied by the event log. Various automated process discovery methods have been proposed in the past two decades, striking different tradeoffs between scalability, accuracy, and complexity of the resulting models. However, these methods have been evaluated in an ad-hoc manner, employing different datasets, experimental setups, evaluation measures, and baselines, often leading to incomparable conclusions and sometimes unreproducible results due to the use of closed datasets. This article provides a systematic review and comparative evaluation of automated process discovery methods, using an open-source benchmark and covering 12 publicly-available real-life event logs, 12 proprietary real-life event logs, and nine quality metrics. The results highlight gaps and unexplored tradeoffs in the ﬁeld, including the lack of scalability of some methods and a strong divergence in their performance with respect to the different quality metrics used.},
	pages = {686--705},
	number = {4},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {Augusto, Adriano and Conforti, Raffaele and Dumas, Marlon and Rosa, Marcello La and Maggi, Fabrizio Maria and Marrella, Andrea and Mecella, Massimo and Soo, Allar},
	urldate = {2022-11-15},
	date = {2019-04-01},
	langid = {english},
	file = {Augusto et al. - 2019 - Automated Discovery of Process Models from Event L.pdf:/Users/ihar/Documents/Zotero/storage/ASPU7LGH/Augusto et al. - 2019 - Automated Discovery of Process Models from Event L.pdf:application/pdf},
}

@misc{viner_process_2021,
	title = {A Process Mining Software Comparison},
	url = {http://arxiv.org/abs/2007.14038},
	abstract = {www.processmining-software.com is a dedicated website for process mining software comparison and was developed to give practitioners and researchers an overview of commercial tools available on the market. Based on literature review and experimental tool testing, a set of criteria was developed in order to assess the tools' functional capabilities in an objective manner. With our publicly accessible website, we intend to increase the transparency of tool functionality. Being an academic endeavour, the non-commercial nature of the study ensures a less biased assessment as compared with reports from analyst firms.},
	number = {{arXiv}:2007.14038},
	publisher = {{arXiv}},
	author = {Viner, Daniel and Stierle, Matthias and Matzner, Martin},
	urldate = {2022-11-15},
	date = {2021-02-04},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2007.14038 [cs]},
	keywords = {Computer Science - Software Engineering, Computer Science - Human-Computer Interaction},
	file = {Viner et al. - 2021 - A Process Mining Software Comparison.pdf:/Users/ihar/Documents/Zotero/storage/LSERD5DW/Viner et al. - 2021 - A Process Mining Software Comparison.pdf:application/pdf},
}

@article{cheng_scalable_2020,
	title = {Scalable Discovery of Hybrid Process Models in a Cloud Computing Environment},
	volume = {13},
	issn = {1939-1374, 2372-0204},
	url = {https://ieeexplore.ieee.org/document/8669858/},
	doi = {10.1109/TSC.2019.2906203},
	abstract = {Process descriptions are used to create products and deliver services. To lead better processes and services, the ﬁrst step is to learn a process model. Process discovery is such a technique which can automatically extract process models from event logs. Although various discovery techniques have been proposed, they focus on either constructing formal models which are very powerful but complex, or creating informal models which are intuitive but lack semantics. In this work, we introduce a novel method that returns hybrid process models to bridge this gap. Moreover, to cope with today’s big event logs, we propose an efﬁcient method, called f-{HMD}, aims at scalable hybrid model discovery in a cloud computing environment. We present the detailed implementation of our approach over the Spark framework, and our experimental results demonstrate that the proposed method is efﬁcient and scalable.},
	pages = {368--380},
	number = {2},
	journaltitle = {{IEEE} Transactions on Services Computing},
	shortjournal = {{IEEE} Trans. Serv. Comput.},
	author = {Cheng, Long and van Dongen, Boudewijn F. and van der Aalst, Wil M.P.},
	urldate = {2022-11-24},
	date = {2020-03-01},
	langid = {english},
	file = {Cheng et al. - 2020 - Scalable Discovery of Hybrid Process Models in a C.pdf:/Users/ihar/Documents/Zotero/storage/SVQ5TTUH/Cheng et al. - 2020 - Scalable Discovery of Hybrid Process Models in a C.pdf:application/pdf},
}

@article{evermann_scalable_2016,
	title = {Scalable Process Discovery Using Map-Reduce},
	volume = {9},
	issn = {1939-1374},
	url = {http://ieeexplore.ieee.org/document/6948229/},
	doi = {10.1109/TSC.2014.2367525},
	abstract = {Process discovery is an approach to extract process models from event logs. Given the distributed nature of modern information systems, event logs are likely to be distributed across different physical machines. Map-Reduce is a scalable approach for efﬁcient computations on distributed data. In this paper we present Map-Reduce implementations of two well-known process mining algorithms to take advantage of the scalability of the Map-Reduce approach. We present the design of a series of mappers and reducers to compute the log-based ordering relations from distributed event logs. These can then be used to discover a process model. We provide experimental results that show the performance and scalability of our implementations.},
	pages = {469--481},
	number = {3},
	journaltitle = {{IEEE} Transactions on Services Computing},
	shortjournal = {{IEEE} Trans. Serv. Comput.},
	author = {Evermann, Joerg},
	urldate = {2022-11-24},
	date = {2016-05-01},
	langid = {english},
	file = {Evermann - 2016 - Scalable Process Discovery Using Map-Reduce.pdf:/Users/ihar/Documents/Zotero/storage/Y8853HJC/Evermann - 2016 - Scalable Process Discovery Using Map-Reduce.pdf:application/pdf},
}

@thesis{abel_lightning_2011,
	location = {Tartu, Estonia},
	title = {Lightning Fast Business Process Simulator},
	pagetotal = {65},
	institution = {University of Tartu},
	type = {phdthesis},
	author = {Abel, Madis},
	date = {2011},
	langid = {english},
	file = {García-Bañuelos and Dumas - Lightning Fast Business Process Simulator.pdf:/Users/ihar/Documents/Zotero/storage/XJ7K9ZM4/García-Bañuelos and Dumas - Lightning Fast Business Process Simulator.pdf:application/pdf},
}

@incollection{daniel_declarative_2013,
	location = {Berlin, Heidelberg},
	title = {Declarative Modeling–An Academic Dream or the Future for {BPM}?},
	volume = {8094},
	isbn = {978-3-642-40175-6 978-3-642-40176-3},
	url = {http://link.springer.com/10.1007/978-3-642-40176-3_26},
	abstract = {Declarative modeling has attracted much attention over the last years, resulting in the development of several academic declarative modeling techniques and tools. The absence of empirical evaluations on their use and usefulness, however, raises the question whether practitioners are attracted to using those techniques. In this paper, we present a study on what practitioners think of declarative modeling. We show that the practitioners we involved in this study are receptive to the idea of a hybrid approach combining imperative and declarative techniques, rather than making a full shift from the imperative to the declarative paradigm. Moreover, we report on requirements, use cases, limitations, and tool support of such a hybrid approach. Based on the gained insight, we propose a research agenda for the development of this novel modeling approach.},
	pages = {307--322},
	booktitle = {Business Process Management},
	publisher = {Springer Berlin Heidelberg},
	author = {Reijers, Hajo A. and Slaats, Tijs and Stahl, Christian},
	editor = {Daniel, Florian and Wang, Jianmin and Weber, Barbara},
	urldate = {2022-11-25},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-40176-3_26},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Reijers et al. - 2013 - Declarative Modeling–An Academic Dream or the Futu.pdf:/Users/ihar/Documents/Zotero/storage/68BB2JVX/Reijers et al. - 2013 - Declarative Modeling–An Academic Dream or the Futu.pdf:application/pdf},
}

@article{van_der_aalst_declarative_2009,
	title = {Declarative workflows: Balancing between flexibility and support},
	volume = {23},
	issn = {1865-2034},
	url = {http://link.springer.com/10.1007/s00450-009-0057-9},
	doi = {10.1007/s00450-009-0057-9},
	shorttitle = {Declarative workflows},
	abstract = {Today’s process-aware information systems tend to either support business processes or provide ﬂexibility. Classical workﬂow management systems offer good process support as long as the processes are structured and do not require much ﬂexibility. Information systems that allow for ﬂexibility have a tendency to lack process-related support. If systems offer guidance, then they are typically also inclined to “enforce guidelines” and are perceived as inﬂexible. Moreover, implementing ﬂexible systems is far from trivial. This paper will show that using a more declarative approach can assist in a better balance between ﬂexibility and support. This is demonstrated by presenting the Declare framework that aims to take care of the full spectrum of ﬂexibility while at the same time supports the user using recommendations and other process-mining-based diagnostics.},
	pages = {99--113},
	number = {2},
	journaltitle = {Computer Science - Research and Development},
	shortjournal = {Comp. Sci. Res. Dev.},
	author = {van der Aalst, W. M. P. and Pesic, M. and Schonenberg, H.},
	urldate = {2022-11-25},
	date = {2009-05},
	langid = {english},
	file = {van der Aalst et al. - 2009 - Declarative workflows Balancing between flexibili.pdf:/Users/ihar/Documents/Zotero/storage/PQWGWK4M/van der Aalst et al. - 2009 - Declarative workflows Balancing between flexibili.pdf:application/pdf},
}

@article{murata_petri_1989,
	title = {Petri nets: Properties, analysis and applications},
	volume = {77},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/24143/},
	doi = {10.1109/5.24143},
	shorttitle = {Petri nets},
	pages = {541--580},
	number = {4},
	journaltitle = {Proceedings of the {IEEE}},
	shortjournal = {Proc. {IEEE}},
	author = {Murata, T.},
	urldate = {2022-11-25},
	date = {1989-04},
	langid = {english},
	file = {Murata - 1989 - Petri nets Properties, analysis and applications.pdf:/Users/ihar/Documents/Zotero/storage/LUPS4KZT/Murata - 1989 - Petri nets Properties, analysis and applications.pdf:application/pdf},
}

% @misc{noauthor_business_2010,
% 	title = {Business Process Model and Notation ({BPMN}), Version 2.0},
% 	url = {http://www.omg.org/spec/BPMN/2.0},
% 	urldate = {2022-11-25},
% 	date = {2010},
% 	langid = {english},
% 	file = {Business Process Model and Notation (BPMN), Versio.pdf:/Users/ihar/Documents/Zotero/storage/Y7A764WH/Business Process Model and Notation (BPMN), Versio.pdf:application/pdf},
% }

@misc{noauthor_bpmn_2014,
	author = {{Object  Management Group}}, title = {Business Process Model and Notation ({BPMN}), Version 2.0},
	url = {https://www.omg.org/spec/BPMN/2.0.2/PDF},
	version = {2.0.2},
	date = {2014},
	langid = {english},
	file = {Business Process Model and Notation (BPMN), Versio.pdf:/Users/ihar/Documents/Zotero/storage/SMH9B8T3/Business Process Model and Notation (BPMN), Versio.pdf:application/pdf},
}


@article{van_der_aalst_workflow_2004,
	title = {Workflow mining: discovering process models from event logs},
	volume = {16},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/1316839/},
	doi = {10.1109/TKDE.2004.47},
	shorttitle = {Workflow mining},
	abstract = {Contemporary workflow management systems are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a complicated time-consuming process and, typically, there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, we have developed techniques for discovering workflow models. The starting point for such techniques is a so-called “workflow log” containing information about the workflow process as it is actually being executed. We present a new algorithm to extract a process model from such a log and represent it in terms of a Petri net. However, we will also demonstrate that it is not possible to discover arbitrary workflow processes. In this paper, we explore a class of workflow processes that can be discovered. We show that the -algorithm can successfully mine any workflow represented by a so-called {SWF}-net.},
	pages = {1128--1142},
	number = {9},
	journaltitle = {{IEEE} Transactions on Knowledge and Data Engineering},
	shortjournal = {{IEEE} Trans. Knowl. Data Eng.},
	author = {van der Aalst, W. and Weijters, T. and Maruster, L.},
	urldate = {2022-11-25},
	date = {2004-09},
	langid = {english},
	file = {van der Aalst et al. - 2004 - Workflow mining discovering process models from e.pdf:/Users/ihar/Documents/Zotero/storage/FPQ3FE2F/van der Aalst et al. - 2004 - Workflow mining discovering process models from e.pdf:application/pdf},
}

@report{noauthor_ieee_nodate,
	title = {{IEEE} Standard for a Software Quality Metrics Methodology},
	url = {http://ieeexplore.ieee.org/document/749159/},
	abstract = {A methodology for establishing quality requirements and identifying, implementing, analyzing and validating the process and product software quality metrics is defined. The methodology spans the entire software life cycle.},
	institution = {{IEEE}},
	urldate = {2022-11-26},
	langid = {english},
	doi = {10.1109/IEEESTD.1998.243394},
	note = {{ISBN}: 9781559375290 9780738115108},
	file = {IEEE Standard for a Software Quality Metrics Metho.pdf:/Users/ihar/Documents/Zotero/storage/ARGC6FPC/IEEE Standard for a Software Quality Metrics Metho.pdf:application/pdf},
}

@article{kruchten_technical_2012,
	title = {Technical Debt: From Metaphor to Theory and Practice},
	volume = {29},
	issn = {0740-7459},
	url = {http://ieeexplore.ieee.org/document/6336722/},
	doi = {10.1109/MS.2012.167},
	shorttitle = {Technical Debt},
	pages = {18--21},
	number = {6},
	journaltitle = {{IEEE} Software},
	shortjournal = {{IEEE} Softw.},
	author = {Kruchten, Philippe and Nord, Robert L. and Ozkaya, Ipek},
	urldate = {2022-11-26},
	date = {2012-11},
	langid = {english},
	file = {Kruchten et al. - 2012 - Technical Debt From Metaphor to Theory and Practi.pdf:/Users/ihar/Documents/Zotero/storage/GGU8PJ4F/Kruchten et al. - 2012 - Technical Debt From Metaphor to Theory and Practi.pdf:application/pdf},
}

@inproceedings{chang_kubernetes-based_2017,
	location = {Singapore},
	title = {A Kubernetes-Based Monitoring Platform for Dynamic Cloud Resource Provisioning},
	isbn = {978-1-5090-5019-2},
	url = {http://ieeexplore.ieee.org/document/8254046/},
	doi = {10.1109/GLOCOM.2017.8254046},
	abstract = {Recently, more and more network operators have deployed cloud environment to implement network operations centers that monitor the status of their large-scale mobile or wireline networks. Typically, the cloud environment adopts container-based virtualization that uses Docker for container packaging with Kubernetes for multihost Docker container management. In such a container-based environment, it is important that the Kubernetes can dynamically monitor the resource requirements and/or usage of the running applications, and then adjust the resource provisioned to the managed containers accordingly. Currently, Kubernetes provides a naive dynamic resource-provisioning mechanism which only considers {CPU} utilization and thus is not effective. This paper aims at developing a generic platform to facilitate dynamic resource-provisioning based on Kubernetes. Our platform contains the following three features. First, our platform includes a comprehensive monitoring mechanism that integrates and provides the relatively complete system resource utilization and application {QoS} metrics to the resource-provisioning algorithm to make the better provisioning strategy. Second, our platform modularizes the operation of dynamic resource-provisioning operation so that the users can easily deploy a newly designed algorithm to replace an existing one in our platform. Third, the dynamic resource-provisioning operation in our platform is implemented as a control loop which can consequently be applied to all the running application following a user-deﬁned time interval without other manual conﬁguration.},
	eventtitle = {2017 {IEEE} Global Communications Conference ({GLOBECOM} 2017)},
	pages = {1--6},
	booktitle = {{GLOBECOM} 2017 - 2017 {IEEE} Global Communications Conference},
	publisher = {{IEEE}},
	author = {Chang, Chia-Chen and Yang, Shun-Ren and Yeh, En-Hau and Lin, Phone and Jeng, Jeu-Yih},
	urldate = {2022-11-26},
	date = {2017-12},
	langid = {english},
	file = {Chang et al. - 2017 - A Kubernetes-Based Monitoring Platform for Dynamic.pdf:/Users/ihar/Documents/Zotero/storage/VLTCHK7N/Chang et al. - 2017 - A Kubernetes-Based Monitoring Platform for Dynamic.pdf:application/pdf},
}

@book{van_vliet_software_2007,
	title = {Software Engineering: Principles and Practice},
	publisher = {Wiley},
	author = {van Vliet, Hans},
	date = {2007},
	langid = {english},
	file = {van Vliet - Software Engineering Principles and Practice.pdf:/Users/ihar/Documents/Zotero/storage/UZKBD6IP/van Vliet - Software Engineering Principles and Practice.pdf:application/pdf},
}

@inproceedings{dua_virtualization_2014,
	location = {Boston, {MA}, {USA}},
	title = {Virtualization vs Containerization to Support {PaaS}},
	isbn = {978-1-4799-3766-0},
	url = {http://ieeexplore.ieee.org/document/6903537/},
	doi = {10.1109/IC2E.2014.41},
	abstract = {{PaaS} vendors face challenges in efﬁciently providing services with the growth of their offerings. In this paper, we explore how {PaaS} vendors are using containers as a means of hosting Apps. The paper starts with a discussion of {PaaS} Use case and the current adoption of Container based {PaaS} architectures with the existing vendors. We explore various container implementations - Linux Containers, Docker, Warden Container, lmctfy and {OpenVZ}. We look at how each of this implementation handle Process, {FileSystem} and Namespace isolation. We look at some of the unique features of each container and how some of them reuse base Linux Container implementation or differ from it. We also explore how {IaaSlayer} itself has started providing support for container lifecycle management along with Virtual Machines. In the end, we look at factors affecting container implementation choices and some of the features missing from the existing implementations for the next generation {PaaS}.},
	eventtitle = {2014 {IEEE} International Conference on Cloud Engineering ({IC}2E)},
	pages = {610--614},
	booktitle = {2014 {IEEE} International Conference on Cloud Engineering},
	publisher = {{IEEE}},
	author = {Dua, Rajdeep and Raja, A Reddy and Kakadia, Dharmesh},
	urldate = {2022-11-26},
	date = {2014-03},
	langid = {english},
	file = {Dua et al. - 2014 - Virtualization vs Containerization to Support PaaS.pdf:/Users/ihar/Documents/Zotero/storage/63MIBGM4/Dua et al. - 2014 - Virtualization vs Containerization to Support PaaS.pdf:application/pdf},
}

@inproceedings{macarthy_empirical_2020,
	location = {Portoroz, Slovenia},
	title = {An Empirical Taxonomy of {DevOps} in Practice},
	isbn = {978-1-72819-532-2},
	url = {https://ieeexplore.ieee.org/document/9226359/},
	doi = {10.1109/SEAA51224.2020.00046},
	abstract = {{DevOps} is described as a software engineering culture and philosophy that utilises cross-functional teams to build, test and release software faster and more reliably through automation. Research shows that its adoption speeds up software delivery time, improve quality, security, and collaboration in software development. One controversial issue has been whether {DevOps} is an organisation-wide culture or a job description. As {DevOps} is an emerging concept, its deﬁnitions and best practices are still hazy, making its implementation in practice less informed and somewhat risky. The rising trend of {DevOps} adoption among software development practitioners therefore heightens the need for in-depth investigation into its implementation.This paper seeks to contribute to the above by critically examining {DevOps} implementation in practice through an exploratory case study, based on interviews with 11 industry practitioners across nine organisations. Transcripts of interviews were coded and analysed using a method informed by Grounded Theory. This study provides an empirical taxonomy of {DevOps} implementation, describing developers’ interaction with On-premises Ops, Outsourced Ops, {DevOps} teams, and {DevOps} bridge teams. We present a novel mapping of the approaches to on-premises and cloud-based deployments, and identiﬁed the facilitators of {DevOps} practices in the different modes. We further identiﬁed three distinct groups of activities in the fourth mode: provisioning and maintenance of physical systems, function virtualisation and creation of automated pipelines, and development, deployment and maintenance of applications, which may have given rise to the implementation of {DevOps} as bridge teams. Interviewees claimed these distinctions allowed developers to focus on delivering value for the business.},
	eventtitle = {2020 46th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	pages = {221--228},
	booktitle = {2020 46th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	publisher = {{IEEE}},
	author = {Macarthy, Ruth W. and Bass, Julian M.},
	urldate = {2022-11-26},
	date = {2020-08},
	langid = {english},
	file = {Macarthy and Bass - 2020 - An Empirical Taxonomy of DevOps in Practice.pdf:/Users/ihar/Documents/Zotero/storage/IBNHAJFI/Macarthy and Bass - 2020 - An Empirical Taxonomy of DevOps in Practice.pdf:application/pdf},
}

@book{humble_continuous_2010,
	location = {Upper Saddle River, {NJ}},
	title = {Continuous delivery: reliable software releases through build, test, and deployment automation},
	isbn = {978-0-321-60191-9},
	shorttitle = {Continuous delivery},
	pagetotal = {463},
	publisher = {Addison-Wesley},
	author = {Humble, Jez and Farley, David},
	date = {2010},
	keywords = {Computer software, Development, Reliability, Testing},
}

@online{noauthor_docker_2022,
	title = {Docker: Accelerated, Containerized Application Development},
	url = {https://www.docker.com/},
	shorttitle = {Docker},
	abstract = {Docker is a platform designed to help developers build, share, and run modern applications. We handle the tedious setup, so you can focus on the code.},
	urldate = {2022-11-26},
	date = {2022-05-10},
	langid = {american},
}

@online{kubernetes_website,
	title = {Production-Grade Container Orchestration},
    author = {The Kubernetes Authors},
	url = {https://kubernetes.io/},
	abstract = {Production-Grade Container Orchestration},
	titleaddon = {Kubernetes},
	urldate = {2022-11-26},
	langid = {english},
	file = {Snapshot:/Users/ihar/Documents/Zotero/storage/QGIWGI2Q/kubernetes.io.html:text/html},
}

@article{baskerville_soft_2009,
	title = {Soft design science methodology},
	abstract = {This paper proposes and evaluates a soft systems approach to design science research. Soft Design Science provides an approach to the development of new ways to improve human organizations, especially with consideration for social aspects, through the activities of design, development, instantiation, evaluation and evolution of a technological artifact. The Soft Design Science approach merges the common design science research process (design, build-artifact, evaluation) together with the iterative soft systems methodology. The design-build artifactevaluation process is iterated until the specific requirements are met. The generalized requirements are adjusted as the process continues to keep alignment with the specific requirements. In the end, the artifact represents a general solution to a class of problems shown to operate in one instance of that class of problems. The proposed methodology is evaluated by an analysis of how it differs from, and could have informed and improved, a published design science study, which used a design-oriented action research method.},
	pages = {11},
	author = {Baskerville, Richard and Pries-Heje, Jan and Venable, John},
	date = {2009},
	langid = {english},
	file = {Baskerville et al. - Soft design science methodology.pdf:/Users/ihar/Documents/Zotero/storage/AG8JJLSJ/Baskerville et al. - Soft design science methodology.pdf:application/pdf},
}

@article{march_design_1995,
	title = {Design and natural science research on information technology},
	volume = {15},
	issn = {01679236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0167923694000412},
	doi = {10.1016/0167-9236(94)00041-2},
	abstract = {Research in {IT} must address the design tasks faced by practitioners. Real problems must be properly conceptualized and represented, appropriate techniques for their solution must be constructed, and solutions must be implemented and evaluated using appropriate criteria. If significant progress is to be made, {IT} research must also develop an understanding of how and why {IT} systems work or do not work. Such an understanding must tie together natural laws governing {IT} systems with natural laws governing the environments in which they operate. This paper presents a two dimensional framework for research in information technology. The first dimension is based on broad types of design and natural science research activities: build, evaluate, theorize, and justify. The second dimension is based on broad types of outputs produced by design research: representational constructs, models, methods, and instantiations. We argue that both design science and natural science activities are needed to insure that {IT} research is both relevant and effective.},
	pages = {251--266},
	number = {4},
	journaltitle = {Decision Support Systems},
	shortjournal = {Decision Support Systems},
	author = {March, Salvatore T. and Smith, Gerald F.},
	urldate = {2022-11-27},
	date = {1995-12},
	langid = {english},
	file = {March and Smith - 1995 - Design and natural science research on information.pdf:/Users/ihar/Documents/Zotero/storage/ZYDWMPFY/March and Smith - 1995 - Design and natural science research on information.pdf:application/pdf},
}

@inbook{hevner_design_2010,
	location = {Boston, {MA}},
	title = {Design and Creativity},
	volume = {22},
	isbn = {978-1-4419-5652-1 978-1-4419-5653-8},
	url = {http://link.springer.com/10.1007/978-1-4419-5653-8_11},
	pages = {145--156},
	booktitle = {Design Research in Information Systems},
	publisher = {Springer {US}},
	author = {Hevner, Alan and Chatterjee, Samir},
	bookauthor = {Hevner, Alan and Chatterjee, Samir},
	urldate = {2022-11-27},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-4419-5653-8_11},
	note = {Series Title: Integrated Series in Information Systems},
	file = {Hevner and Chatterjee - 2010 - Design and Creativity.pdf:/Users/ihar/Documents/Zotero/storage/L6ZBSL32/Hevner and Chatterjee - 2010 - Design and Creativity.pdf:application/pdf},
}

@article{pries-heje_strategies_2008,
	title = {Strategies for Design Science Research Evaluation},
	abstract = {Seminal works in the application of design science research ({DSR}) in {IS} emphasize the importance of evaluation. However, discussion of evaluation activities and methods is limited and typically assumes an ex post perspective, in which evaluation occurs after the construction of an {IS} artifact. Such perspectives can assume that the evaluation is an empirical process and its methods can be selected in the same way as empirical research methods. In this paper, we analyze a broader range of evaluation strategies, which includes ex ante (prior to artifact construction) evaluation. This broader view is developed as a strategic {DSR} evaluation framework, which expands evaluation choices for {IS} {DSR} researchers, and also adds emphasis to strategies for evaluating design processes in addition to design products, using well-known quality criteria as an important asset. The framework encompasses both ex ante and ex post orientations as well as naturalistic settings (e.g., case studies) and artificial settings (e.g., lab experiments) for {DSR} evaluation. The framework proposed offers a strategic view of {DSR} evaluation that is useful in analyzing published studies, and also in surfacing the evaluation opportunities that present themselves to {IS} {DSR} researchers.},
	pages = {13},
	author = {Pries-Heje, Jan and Baskerville, Richard and Venable, John R},
	date = {2008},
	langid = {english},
	file = {Pries-Heje et al. - Strategies for Design Science Research Evaluation.pdf:/Users/ihar/Documents/Zotero/storage/9TGX6HUC/Pries-Heje et al. - Strategies for Design Science Research Evaluation.pdf:application/pdf},
}

@online{noauthor_system_nodate,
	title = {System and Service Manager},
	url = {https://systemd.io/},
	urldate = {2022-11-27},
	file = {System and Service Manager:/Users/ihar/Documents/Zotero/storage/GH6WINDI/systemd.io.html:text/html},
}

@online{noauthor_sonarqube_nodate,
	title = {{SonarQube}. Self-managed static analysis tool for continuous codebase inspection},
	url = {https://www.sonarsource.com/products/sonarqube/},
	abstract = {Empower development teams with a solution that deeply integrates into your enterprise environment and enables you to deploy clean code consistently, reliably.},
	urldate = {2022-11-27},
	langid = {english},
	file = {Snapshot:/Users/ihar/Documents/Zotero/storage/LDJ3ANLY/sonarqube.html:text/html},
}

@article{kitchenham_evaluating_1996,
	title = {Evaluating software engineering methods and tool part 1},
	volume = {21},
	abstract = {This discussion has identified nine distinct evaluation types: 1. Quantitative experiment: A n investigation of the quantitative impact of methods/tools organised as a formal experiment. 2. Quantitative case study: A n investigation of the quantitative impact of methods/tools organised as a case study.},
	pages = {5},
	number = {1},
	journaltitle = {{ACM} {SIGSOFT}},
	author = {Kitchenham, Barbara Ann},
	date = {1996},
	langid = {english},
	file = {Kitchenham - Evaluating software engineering methods and tool p.pdf:/Users/ihar/Documents/Zotero/storage/H56Y6UWU/Kitchenham - Evaluating software engineering methods and tool p.pdf:application/pdf},
}

@online{noauthor_clean_nodate,
	title = {Clean as You Code {\textbar} {SonarQube} Docs},
	url = {https://docs.sonarqube.org/latest/user-guide/clean-as-you-code/},
	urldate = {2022-12-01},
	file = {Clean as You Code | SonarQube Docs:/Users/ihar/Documents/Zotero/storage/WFFL43HA/clean-as-you-code.html:text/html},
}

@misc{campbell_new_2021,
	title = {A new way of measuring understandability},
	abstract = {Cyclomatic Complexity was initially formulated as a measurement of the “testability and maintainability” of the control flow of a module. While it excels at measuring the former, its underlying mathematical model is unsatisfactory at producing a value that measures the latter. This white paper describes a new metric that breaks from the use of mathematical models to evaluate code in order to remedy Cyclomatic Complexity’s shortcomings and produce a measurement that more accurately reflects the relative difficulty of understanding, and therefore of maintaining methods, classes, and applications.},
	author = {Campbell, G Ann},
	date = {2021},
	langid = {english},
	file = {Campbell and Sa - A new way of measuring understandability.pdf:/Users/ihar/Documents/Zotero/storage/96C3YYNF/Campbell and Sa - A new way of measuring understandability.pdf:application/pdf},
}

@online{noauthor_pep_2001,
	title = {{PEP} 8 – Style Guide for Python Code {\textbar} peps.python.org},
	url = {https://peps.python.org/pep-0008/},
	urldate = {2022-12-17},
	date = {2001},
	file = {PEP 8 – Style Guide for Python Code | peps.python.org:/Users/ihar/Documents/Zotero/storage/W7V2E94N/pep-0008.html:text/html},
}

@online{noauthor_pep_2012,
	title = {{PEP} 423 – Naming conventions and recipes related to packaging {\textbar} peps.python.org},
	url = {https://peps.python.org/pep-0423/},
	urldate = {2022-12-17},
	date = {2012},
	file = {PEP 423 – Naming conventions and recipes related to packaging | peps.python.org:/Users/ihar/Documents/Zotero/storage/933LRFIA/pep-0423.html:text/html},
}

@online{noauthor_pep_2004,
	title = {{PEP} 20 – The Zen of Python {\textbar} peps.python.org},
	url = {https://peps.python.org/pep-0020/#easter-egg},
	urldate = {2022-12-17},
	date = {2004},
	file = {PEP 20 – The Zen of Python | peps.python.org:/Users/ihar/Documents/Zotero/storage/XC8CWIFK/pep-0020.html:text/html},
}

@online{noauthor_pep_nodate,
	title = {{PEP} 257 – Docstring Conventions {\textbar} peps.python.org},
	url = {https://peps.python.org/pep-0257/},
	urldate = {2022-12-17},
	file = {PEP 257 – Docstring Conventions | peps.python.org:/Users/ihar/Documents/Zotero/storage/42NMYTU8/pep-0257.html:text/html},
}

@online{noauthor_yaml_nodate,
	title = {{YAML}: {YAML} Ain't Markup Language},
	url = {https://yaml.org/},
	abstract = {{YAML} is a human-friendly data serialization language for all programming languages.},
	urldate = {2022-12-17},
	file = {The Official YAML Web Site:/Users/ihar/Documents/Zotero/storage/SED2QEIF/yaml.org.html:text/html},
}

@book{solingen_goalquestionmetric_1999,
	location = {London},
	title = {The goal/question/metric method: a practical guide for quality improvement of software development},
	isbn = {978-0-07-709553-6},
	shorttitle = {The goal/question/metric method},
	pagetotal = {199},
	publisher = {The {McGraw}-Hill Companies},
	author = {Solingen, Rini van and Berghout, Egon and Berghout, Egon W.},
	date = {1999},
	langid = {english},
	file = {Solingen et al. - 1999 - The goalquestionmetric method a practical guide.pdf:/Users/ihar/Documents/Zotero/storage/JIHI4IMR/Solingen et al. - 1999 - The goalquestionmetric method a practical guide.pdf:application/pdf},
}

@article{xia_measuring_2018,
	title = {Measuring Program Comprehension: A Large-Scale Field Study with Professionals},
	volume = {44},
	issn = {1939-3520},
	doi = {10.1109/TSE.2017.2734091},
	shorttitle = {Measuring Program Comprehension},
	abstract = {During software development and maintenance, developers spend a considerable amount of time on program comprehension activities. Previous studies show that program comprehension takes up as much as half of a developer's time. However, most of these studies are performed in a controlled setting, or with a small number of participants, and investigate the program comprehension activities only within the {IDEs}. However, developers' program comprehension activities go well beyond their {IDE} interactions. In this paper, we extend our {ActivitySpace} framework to collect and analyze Human-Computer Interaction ({HCI}) data across many applications (not just the {IDEs}). We follow Minelli et al.'s approach to assign developers' activities into four categories: navigation, editing, comprehension, and other. We then measure the comprehension time by calculating the time that developers spend on program comprehension, e.g., inspecting console and breakpoints in {IDE}, or reading and understanding tutorials in web browsers. Using this approach, we can perform a more realistic investigation of program comprehension activities, through a field study of program comprehension in practice across a total of seven real projects, on 78 professional developers, and amounting to 3,148 working hours. Our study leverages interaction data that is collected across many applications by the developers. Our study finds that on average developers spend 58 percent of their time on program comprehension activities, and that they frequently use web browsers and document editors to perform program comprehension activities. We also investigate the impact of programming language, developers' experience, and project phase on the time that is spent on program comprehension, and we find senior developers spend significantly less percentages of time on program comprehension than junior developers. Our study also highlights the importance of several research directions needed to reduce program comprehension time, e.g., building automatic detection and improvement of low quality code and documentation, construction of software-engineering-specific search engines, designing better {IDEs} that help developers navigate code and browse information more efficiently, etc.},
	pages = {951--976},
	number = {10},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Xia, Xin and Bao, Lingfeng and Lo, David and Xing, Zhenchang and Hassan, Ahmed E. and Li, Shanping},
	date = {2018-10},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
	keywords = {Browsers, Debugging, field study, inference model, Maintenance engineering, Navigation, Program comprehension, Programming, Software, Time measurement},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/N6TQQZSP/7997917.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/7KTQIUWG/Xia et al. - 2018 - Measuring Program Comprehension A Large-Scale Fie.pdf:application/pdf},
}

@article{ebert_cyclomatic_2016,
	title = {Cyclomatic Complexity},
	volume = {33},
	issn = {1937-4194},
	doi = {10.1109/MS.2016.147},
	abstract = {The cyclomatic complexity ({CC}) metric measures the number of linearly independent paths through a piece of code. Although Thomas {McCabe} developed {CC} for procedural languages, its popularity has endured throughout the object-oriented era. That said, {CC} is one of the most controversial metrics, shunned for the most part by academia for certain theoretical weaknesses and the belief that it's no more useful than a simple “lines of code” metric. However, most metrics collection tools support its collection, and, paradoxically, industry uses it extensively. So, why is this the case? This question also leads to fundamental perennial questions about industry's exposure to academic opinion and whether academic research fails to take account of software development's daily practicalities. Maybe industry is simply looking for straightforward, widely understood metrics?},
	pages = {27--29},
	number = {6},
	journaltitle = {{IEEE} Software},
	author = {Ebert, Christof and Cain, James and Antoniol, Giuliano and Counsell, Steve and Laplante, Phillip},
	date = {2016-11},
	note = {Conference Name: {IEEE} Software},
	keywords = {Software engineering, Blogs, Complexity theory, cyclomatic complexity, software development, Software development, software engineering, software industry, Software measurement, Software testing},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/TFRV9QRM/7725232.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/NBTARY9D/Ebert et al. - 2016 - Cyclomatic Complexity.pdf:application/pdf},
}

@online{noauthor_abbyy_nodate,
	title = {{ABBYY} Timeline. Advanced Process Mining Software},
	url = {https://www.abbyy.com/timeline/},
	abstract = {{ABBYY} Timeline is an {AI}-enabled process mining software: featuring advanced process discovery, task mining, process digital twin, process forecasting capabilities and more.},
	titleaddon = {{ABBYY}},
	urldate = {2022-12-18},
	langid = {american},
	file = {Snapshot:/Users/ihar/Documents/Zotero/storage/CGPM3AQ9/timeline.html:text/html},
}

@online{noauthor_apromore_nodate,
	title = {Apromore. Key Features},
	url = {https://apromore.com/key-features/},
	abstract = {Apromore process mining software key features. Accelerate process modeling, gain process intelligence through monitoring and process simulation},
	titleaddon = {Apromore},
	urldate = {2022-12-18},
	langid = {american},
	file = {Snapshot:/Users/ihar/Documents/Zotero/storage/7RYBC757/key-features.html:text/html},
}

@online{noauthor_aris_nodate,
	title = {{ARIS} Process Mining},
	url = {https://aris-process-mining.com/},
	urldate = {2022-12-18},
	file = {Understand your processes like never before - ARIS Process Mining:/Users/ihar/Documents/Zotero/storage/38ULY6F9/aris-process-mining.com.html:text/html},
}

@online{noauthor_businessoptix_nodate,
	title = {{BusinessOptix} Process Mining},
	url = {https://www.businessoptix.com/process-mining},
	abstract = {Process mining helps you create an approach to improve processes by leveraging empirical evidence to uncover how your processes work in the real world.},
	urldate = {2022-12-18},
	langid = {english},
	file = {Snapshot:/Users/ihar/Documents/Zotero/storage/G56LFUQD/process-mining.html:text/html},
}

@online{noauthor_celonis_nodate,
	title = {Celonis. Process Excellence},
	url = {https://www.celonis.com/solutions/process-excellence/},
	abstract = {Try Celonis {EMS}, our process excellence solution that helps increase productivity, improve compliance and free up working capital.},
	titleaddon = {Celonis},
	urldate = {2022-12-18},
	langid = {english},
	file = {Snapshot:/Users/ihar/Documents/Zotero/storage/2WEGGKE4/process-excellence.html:text/html},
}

@article{tjoa_formal_2011,
	title = {A Formal Approach Enabling Risk-Aware Business Process Modeling and Simulation},
	volume = {4},
	issn = {1939-1374},
	doi = {10.1109/TSC.2010.17},
	abstract = {The effective, efficient and continuous execution of business processes is crucial for meeting entrepreneurial goals. Business process modeling and simulation are used to enable desired business process optimizations. However, current approaches mainly focus on economic aspects while security aspects are dealt with in separate initiatives. This missing interconnection may lead to significant differences in improvement suggestions, such as the differing valuation of security investments (e.g., redundancy of systems). The major contribution of this paper is the introduction of a formal model that is capable of expressing the relations between threats, detection mechanisms, safeguards, recovery measures and their effects on business processes. This novel business process simulation capability paves the way for the evaluation of security investments at process design stage by allowing the consideration of stochastic influences of the occurrence of threats on process activities and resources in a unified way. A stylized business case outlines how our method can be applied to real world scenarios.},
	pages = {153--166},
	number = {2},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Tjoa, Simon and Jakoubi, Stefan and Goluch, Gernot and Kitzler, Gerhard and Goluch, Sigrun and Quirchmayr, Gerald},
	date = {2011-04},
	note = {Conference Name: {IEEE} Transactions on Services Computing},
	keywords = {Biological system modeling, Business continuity, Business process reengineering, Computational modeling, consulting and strategic planning, Risk management, Security, security enablement methods and tools., Unified modeling language},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/TZ43KIIK/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/NDA7LQC5/Tjoa et al. - 2011 - A Formal Approach Enabling Risk-Aware Business Pro.pdf:application/pdf},
}

@article{lin_using_2000,
	title = {Using multi-agent simulation and learning to design new business processes},
	volume = {30},
	issn = {1558-2426},
	doi = {10.1109/3468.844361},
	abstract = {Business process modeling, analysis, and then redesign are the central task in the efforts of re-engineering business processes. Frequently reviewing and promptly changing business processes to adapt to new business environment is the key to maintain agility under the competitive global market. It is imperative to enhance the adaptability of business processes. This paper proposes a multi-agent information system based on Swarm, a multi-agent simulation platform, to simulate business processes and incorporate reinforcement learning to obtain better process adaptability. The resulting system, called {BPSLS}, is elaborated and evaluated by the order fulfilment process in supply chain networks.},
	pages = {380--384},
	number = {3},
	journaltitle = {{IEEE} Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
	author = {Lin, Fu-ren and Pai, Yu-Hua},
	date = {2000-05},
	note = {Conference Name: {IEEE} Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
	keywords = {Analytical models, Business process re-engineering, Globalization, Humans, Information systems, Learning, Multiagent systems, Process design, Supply chains, Technological innovation},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/LBQSVX7L/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/HU9NE8IZ/Lin and Pai - 2000 - Using multi-agent simulation and learning to desig.pdf:application/pdf},
}

@article{lee_comprehensive_2020,
	title = {Comprehensive Simulation and Redesign System for Business Process and Organizational Structure},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3000248},
	abstract = {Even though the extremely uncertain current global business environment requires organizations to change their business processes and organizational structures to adapt to their extremely uncertain and complex environments, existing methodology and system cannot support this problem. This paper presents a comprehensive simulation and redesign system to simulate business processes and organizational structure simultaneously and derive the most process-oriented organizational structure efficiently. The methodology and system suggested in this study can predict the effects of changing business processes and organizational structures through the simulation and derive appropriate and practical organizational structures that execute current processes efficiently through the genetic algorithm. Existing business process researches have the limitations that they rarely have considered the effects of organizational structure on the performance, and this study have outstanding academic contribution in solving the problem systematically using simulation and optimization techniques.},
	pages = {106322--106333},
	journaltitle = {{IEEE} Access},
	author = {Lee, Seunghoon and Choi, Injun and Kim, Hokyeom and Lim, Jitaek and Sung, Sanghyun},
	date = {2020},
	note = {Conference Name: {IEEE} Access},
	keywords = {Analytical models, Business process re-engineering, business process, business process analysis, Business process simulation, Data mining, Data models, organizational redesign, organizational structure, Organizations, Task analysis},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/SKI3QC54/references.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/EJFXCXM8/Lee et al. - 2020 - Comprehensive Simulation and Redesign System for B.pdf:application/pdf},
}

@inproceedings{yussupov_pattern-based_2020,
	title = {Pattern-based Modelling, Integration, and Deployment of Microservice Architectures},
	doi = {10.1109/EDOC49727.2020.00015},
	abstract = {Microservice-based architectures ({MSAs}) gained momentum in industrial and research communities since finer-grained and more independent components foster reuse and reduce time to market. However, to come from the design of {MSAs} to running applications, substantial knowledge and technology-specific expertise in the deployment and integration of microservices is needed. In this paper, we propose a model-driven and pattern-based approach for composing microservices, which facilitates the transition from architectural models to running deployments. Using a unified modelling for {MSAs}, including both their integration based on Enterprise Integration Patterns ({EIPs}) and deployment aspects, our approach enables automatically generating the artefacts for deploying microservice compositions. This helps abstracting away the underlying infrastructure including container orchestration platforms and middleware layer for service integration. To validate the feasibility of our approach, we illustrate its prototypical implementation, with Kubernetes used as container orchestration system and {OpenFaaS} used for managing integration logic, and we present a case study.},
	eventtitle = {2020 {IEEE} 24th International Enterprise Distributed Object Computing Conference ({EDOC})},
	pages = {40--50},
	booktitle = {2020 {IEEE} 24th International Enterprise Distributed Object Computing Conference ({EDOC})},
	author = {Yussupov, Vladimir and Breitenbücher, Uwe and Krieger, Christoph and Leymann, Frank and Soldani, Jacopo and Wurster, Michael},
	date = {2020-10},
	note = {{ISSN}: 2325-6362},
	keywords = {Programming, Task analysis, Communication channels, Containers, Enterprise Integration Pattern, Microservice Architecture, Model-driven Engineering, Publish-subscribe, Routing, Service Composition, Standards},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/D8GVNPSW/9233043.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/PBF8W55P/Yussupov et al. - 2020 - Pattern-based Modelling, Integration, and Deployme.pdf:application/pdf},
}

@article{sivrikaya_internet_2019,
	title = {Internet of Smart City Objects: A Distributed Framework for Service Discovery and Composition},
	volume = {7},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2019.2893340},
	shorttitle = {Internet of Smart City Objects},
	abstract = {Smart cities generally aim at efficiently organizing and managing city resources through a digital layer on top of the legacy infrastructure. As the digitalization trend goes on with an increasing pace and with the involvement of a diverse set of actors, proper management of this digital layer as well as the services deployed over it becomes ever more crucial. This paper presents our methodology of transforming the complex smart city concept and its digital layer into a structured model for creating a dynamic and adaptive service ecosystem in the digital cities of the future. An overview of the smart city concept and the three-tier architecture that emerges through the digitalization of cities is presented first, together with the main challenges in attaining coherent smart city service environments that can avoid fragmentation, ensure scalability, and allow reuse. The three major enablers that are identified in this direction are 1) a semantic functional description of city objects, representing physical devices or abstract services; 2) a distributed service directory that embodies available city services for service lookup and discovery; and 3) planning tools for selecting and chaining basic services to compose new complex services. For each of these, a high-level overview of the available tools and results from the research literature are provided as well as the relevant standards. This overview is complemented with our own approach and design choices in project {ISCO} (Internet of smart city objects). Through the implementation of two distinct use cases, this paper illustrates how {ISCO} components can jointly enrich service creation and consumption of various stakeholders in smart cities.},
	pages = {14434--14454},
	journaltitle = {{IEEE} Access},
	author = {Sivrikaya, Fikret and Ben-Sassi, Nizar and Dang, Xuan-Thuy and Görür, Orhan Can and Kuster, Christian},
	date = {2019},
	note = {Conference Name: {IEEE} Access},
	keywords = {Standards, adaptive planning, Europe, Interoperability, semantic service description, service composition, service discovery, Smart cities, smart city objects, Tools},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/N5HUFEQG/8616795.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/E3A6R7DU/Sivrikaya et al. - 2019 - Internet of Smart City Objects A Distributed Fram.pdf:application/pdf},
}

@article{sebrechts_service_2021,
	title = {Service Relationship Orchestration: Lessons Learned From Running Large Scale Smart City Platforms on Kubernetes},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3115438},
	shorttitle = {Service Relationship Orchestration},
	abstract = {Smart cities aim to make urban life more enjoyable and sustainable but their highly heterogeneous and distributed context creates unique operational challenges. In such an environment, multiple companies work together with government on applications and data streams spanning several management domains. Deploying these applications, each of which consists of several connected services, and maintaining an overview of application topologies remains difficult. Even though cloud modelling languages have been proposed to solve similar issues, they are not well fit for such a heterogeneous environment because they often require an “all or nothing” approach. Moreover, cloud modelling languages add an additional abstraction layer that rarely supports all features of the underlying platform and make it harder to reuse existing knowledge and tools. This research defines service relationships as the key element to modelling applications as topologies of services. We use this definition to pinpoint what is lacking in the state of the art Kubernetes orchestration tools and provide a blueprint for how relationship support can be added to any orchestrator. We present “orcon”, a proof of concept orchestrator that extends the Kubernetes {API} to allow managing relationships between services by adding metadata to service definitions. Our evaluation shows this orchestrator enables lifecycle synchronization and configuration change propagation with an overhead of only 0.44 seconds per service.},
	pages = {133387--133401},
	journaltitle = {{IEEE} Access},
	author = {Sebrechts, Merlijn and Borny, Sander and Wauters, Tim and Volckaert, Bruno and De Turck, Filip},
	date = {2021},
	note = {Conference Name: {IEEE} Access},
	keywords = {Biological system modeling, Containers, service composition, Smart cities, Tools, Cloud computing, Cloud models container orchestration, Collaboration, cross-domain, kubernetes, microservices, service dependencies, service orchestration, smart cities, Topology, topology models, {TOSCA}},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/Z7G3C7NA/9547278.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/2RLN9728/Sebrechts et al. - 2021 - Service Relationship Orchestration Lessons Learne.pdf:application/pdf},
}

@inproceedings{rasheedh_review_2020,
	title = {Review of micro-services architectures and runtime dynamic binding},
	doi = {10.1109/I-SMAC49090.2020.9243335},
	abstract = {The Service Oriented Architecture ({SOA}) is developed as a pattern to distributed computing, enterprise integration and process of e-business in the early decade of 2000. The sudden increase of {SOA} and web services are subjected to the hype and virtual in which each organization has tried for adopting them with no matter in their indeed appropriateness. There are several {SOA} adopted by the user which may lead to massive fail on various attempts that tried for modifying the issues to solutions fit. At present, the microservices act as a recent technique for accomplishing a similar goal established to {SOA} a decade ago. However, the microservice has described a specific design concept in software application as an independent set, modularity, obtaining dynamism, and heterogeneous system integration and distribution development. Therefore, the microservices have provided applications with agility and scalability. This study of literature has discovered such challenges by an evolutionary concept from the {SOA} early years to microservices. This paper has also discussed various models for a run time of dynamic official, web association, a slight extension of association plan and {AI} technique are considered as a view at issues.},
	eventtitle = {2020 Fourth International Conference on I-{SMAC} ({IoT} in Social, Mobile, Analytics and Cloud) (I-{SMAC})},
	pages = {1130--1137},
	booktitle = {2020 Fourth International Conference on I-{SMAC} ({IoT} in Social, Mobile, Analytics and Cloud) (I-{SMAC})},
	author = {Rasheedh, J. Abdul and Saradha, S.},
	date = {2020-10},
	keywords = {Computer architecture, Dynamic Binding, Machine learning, Micro-Service Architecture and Machine Learning Techniques, Monitoring, Run-Time Dynamic Binding, Runtime, Servers, Service-oriented architecture, Time factors, Web Service},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/NMENZWJX/9243335.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/4BGUZPGM/Rasheedh and Saradha - 2020 - Review of micro-services architectures and runtime.pdf:application/pdf},
}

@article{gorski_optimization_2021,
	title = {Optimization of Business Process Execution in Services Architecture: A Systematic Literature Review},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3102668},
	shorttitle = {Optimization of Business Process Execution in Services Architecture},
	abstract = {Web services have become a standard way to provide functions of information systems. The number of web services grows rapidly with the increasing popularity of microservices architecture. In consequence, many business processes are executed entirely through web services. Therefore, optimizing the performance of business process execution may bring many benefits. There are many optimization methods in this area. Our systematic literature review aims to introduce available methods to researchers interested in the optimization of business process execution. We queried four databases: {ACM}, {IEEE} Xplore, Science Direct, and Springer. Out of 12150 initially found papers, we have selected 128 for the review. We have grouped methods presented in those papers into three stages of business process optimization: Resource Allocation, Service Composition, and Service Scheduling. Service Composition attracts the largest group of researchers with a vast majority of 119 articles in it. Moreover, the most popular are genetic algorithms. In general, researchers mainly propose heuristic methods that optimize business processes during run-time. We see the potential for further exploration at both Resource Allocation and Service Scheduling stages.},
	pages = {111833--111852},
	journaltitle = {{IEEE} Access},
	author = {Górski, Tomasz and {WOźniak}, Adrian P.},
	date = {2021},
	note = {Conference Name: {IEEE} Access},
	keywords = {Computer architecture, Reliability, Software, business process, Service-oriented architecture, Business, micro-services, optimization, Optimization, reliability, Resource management},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/IAEL5DSL/9507503.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/P4CZP3Y7/Górski and WOźniak - 2021 - Optimization of Business Process Execution in Serv.pdf:application/pdf},
}

@article{hindman_mesos_nodate,
	title = {Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center},
	abstract = {We present Mesos, a platform for sharing commodity clusters between multiple diverse cluster computing frameworks, such as Hadoop and {MPI}. Sharing improves cluster utilization and avoids per-framework data replication. Mesos shares resources in a ﬁne-grained manner, allowing frameworks to achieve data locality by taking turns reading data stored on each machine. To support the sophisticated schedulers of today’s frameworks, Mesos introduces a distributed two-level scheduling mechanism called resource offers. Mesos decides how many resources to offer each framework, while frameworks decide which resources to accept and which computations to run on them. Our results show that Mesos can achieve near-optimal data locality when sharing the cluster among diverse frameworks, can scale to 50,000 (emulated) nodes, and is resilient to failures.},
	author = {Hindman, Benjamin and Konwinski, Andy and Zaharia, Matei and Ghodsi, Ali and Joseph, Anthony D and Katz, Randy and Shenker, Scott and Stoica, Ion},
	langid = {english},
	file = {Hindman et al. - Mesos A Platform for Fine-Grained Resource Sharin.pdf:/Users/ihar/Documents/Zotero/storage/946CXSCT/Hindman et al. - Mesos A Platform for Fine-Grained Resource Sharin.pdf:application/pdf},
}

@online{noauthor_amqp_nodate,
	title = {{AMQP} Homepage},
	url = {https://www.amqp.org/},
	urldate = {2023-03-31},
	file = {Home | AMQP:/Users/ihar/Documents/Zotero/storage/5IXECBLB/www.amqp.org.html:text/html},
}

@misc{woodside_tutorial_2013,
	title = {Tutorial Introduction to Layered Modeling of Software Performance},
	url = {http://www.sce.carleton.ca/rads/lqns/lqn-documentation/tutorialh.pdf},
	author = {Woodside, Murray},
	date = {2013},
	file = {tutorialh.pdf:/Users/ihar/Documents/Zotero/storage/MWMQNM86/tutorialh.pdf:application/pdf},
}

@article{xue_scalability_2019,
	title = {Scalability analysis of request scheduling in cloud computing},
	volume = {24},
	issn = {1007-0214},
	doi = {10.26599/TST.2018.9010069},
	abstract = {Rapid advancement of distributed computing systems enables complex services in remote computing clusters. Massive applications with large-scale and disparate characteristics also create high requirements for computing systems. Cloud computing provides a series of novel approaches to meet new trends and demands. However, some scalability issues have to be addressed in the request scheduling process and few studies have been conducted to solve these problems. Thus, this study investigates the scalability of the request scheduling process in cloud computing. We provide a theoretical definition of the scalability of this process. By modeling the scheduling server as a stochastic preemptive priority queue, we conduct a comprehensive theoretical and numerical analysis of the scalability metric under different structures and various environment configurations. The comparison and conclusion are expected to shed light on the future design and deployment of the request scheduling process in cloud computing.},
	pages = {249--261},
	number = {3},
	journaltitle = {Tsinghua Science and Technology},
	author = {Xue, Chao and Lin, Chuang and Hu, Jie},
	date = {2019-06},
	note = {Conference Name: Tsinghua Science and Technology},
	keywords = {cloud computing, Cloud computing, Computational modeling, Measurement, model evaluation, Processor scheduling, request scheduling, scalability, Scalability, Scheduling, Servers},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/424U4WWQ/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/38QGXJC9/Xue et al. - 2019 - Scalability analysis of request scheduling in clou.pdf:application/pdf},
}

@online{noauthor_kind_nodate,
	title = {kind},
	url = {https://kind.sigs.k8s.io/},
	abstract = {kind is a tool for running local Kubernetes clusters using Docker container “nodes”.
kind was primarily designed for testing Kubernetes itself, but may be used for local development or {CI}.},
	urldate = {2023-04-09},
	file = {kind:/Users/ihar/Documents/Zotero/storage/Q8BEBRN8/kind.sigs.k8s.io.html:text/html},
}

@misc{van_dongen_bpi_2012,
	title = {{BPI} Challenge 2012},
	rights = {4TU General Terms of Use},
	url = {https://data.4tu.nl/articles/_/12689204/1},
	abstract = {Event log of a loan application process},
	publisher = {Eindhoven University of Technology},
	author = {van Dongen, Boudewijn},
	editora = {Eindhoven University Of Technology},
	editoratype = {collaborator},
	urldate = {2023-04-09},
	date = {2012-04-23},
	langid = {dutch},
	doi = {10.4121/UUID:3926DB30-F712-4394-AEBC-75976070E91F},
	doi = {10.4121/UUID:3926DB30-F712-4394-AEBC-75976070E91F},
	note = {Medium: media types: application/x-gzip, text/xml
Version Number: 1
Type: dataset},
	keywords = {000 Computer science, knowledge \&amp; systems, Business and Management, Business Process Intelligence ({BPI}), {FOS}: Computer and information sciences, {FOS}: Economics and business, {IEEE} Task Force on Process Mining, Information Systems, real life event logs, Time: 2011-10-01T00:38:44.546+02:00 to 2012-03-14T16:04:54.681+01:00},
}

@misc{van_dongen_real-life_2011,
	title = {Real-life event logs - Hospital log},
	rights = {4TU General Terms of Use},
	url = {https://data.4tu.nl/articles/_/12716513/1},
	abstract = {Real life log of a Dutch academic hospital, originally intended for use in the first Business Process Intelligence Contest ({BPIC} 2011)},
	publisher = {Eindhoven University of Technology},
	author = {van Dongen, Boudewijn},
	editora = {Eindhoven University Of Technology},
	editoratype = {collaborator},
	urldate = {2023-04-09},
	date = {2011-03-23},
	langid = {dutch},
	doi = {10.4121/UUID:D9769F3D-0AB0-4FB8-803B-0D1120FFCF54},
	doi = {10.4121/UUID:D9769F3D-0AB0-4FB8-803B-0D1120FFCF54},
	note = {Medium: media types: application/x-gzip, text/xml
Version Number: 1
Type: dataset},
	keywords = {000 Computer science, knowledge \&amp; systems, {FOS}: Computer and information sciences, {IEEE} Task Force on Process Mining, Information Systems, real life event logs, Time: 2005-01-03T00:00:00+01:00 to 2008-03-20T00:00:00+01:00},
}

@misc{van_dongen_bpi_2020,
	title = {{BPI} Challenge 2020: Prepaid Travel Costs},
	rights = {Creative Commons Attribution Non Commercial 4.0 International},
	url = {https://data.4tu.nl/articles/_/12696722/1},
	shorttitle = {{BPI} Challenge 2020},
	abstract = {This file contains the events related to prepaid travel costs Parent item: {BPI} Challenge 2020 The dataset contains events pertaining to two years of travel expense claims. In 2017, events were collected for two departments, in 2018 for the entire university. The various permits and declaration documents (domestic and international declarations, pre-paid travel costs and requests for payment) all follow a similar process flow. After submission by the employee, the request is sent for approval to the travel administration. If approved, the request is then forwarded to the budget owner and after that to the supervisor. If the budget owner and supervisor are the same person, then only one of these steps is taken. In some cases, the director also needs to approve the request.The process finished with either the trip taking place or a payment being requested and payed. On a high level, we distinguish two types of trips, namely domestic and international. For domestic trips, no prior permission is needed, i.e. an employee can undertake these trips and ask for reimbursement of the costs afterwards. For international trips, permission is needed from the supervisor. This permission is obtained by filing a travel-permit and this travel permit should be approved before making any arrangements. To get the costs for a travel reimbursed, a claim is filed. This can be done as soon as costs are actually payed (for example for flights or conference registration fees), or within two months after the trip (for example hotel and food costs which are usually payed on the spot).},
	publisher = {4TU.Centre for Research Data},
	author = {van Dongen, Boudewijn},
	editora = {Eindhoven University Of Technology, Department Of Mathematics \{And\} Computer Science},
	editoratype = {collaborator},
	urldate = {2023-04-10},
	date = {2020-03-26},
	langid = {english},
	doi = {10.4121/UUID:5D2FE5E1-F91F-4A3B-AD9B-9E4126870165},
	doi = {10.4121/UUID:5D2FE5E1-F91F-4A3B-AD9B-9E4126870165},
	note = {Medium: media types: application/x-gzip, text/plain, text/xml
Version Number: 1
Type: dataset},
	keywords = {{BPI} Challenge, Business Process Intelligence ({BPI}), Collection: {BPI} Challenge 2020, Compliance Checking, {FOS}: Computer and information sciences, {IEEE} Task Force on Process Mining, Information Systems, Process Mining, real life event logs, Time: 2017/2018},
}

@book{daigneau_service_2012,
	location = {Upper Saddle River, {NJ}},
	title = {Service design patterns: fundamental design solutions for {SOAP}/{WSDL} and {RESTful} Web services},
	isbn = {978-0-321-54420-9},
	series = {Addison-Wesley signature series},
	shorttitle = {Service design patterns},
	pagetotal = {321},
	publisher = {Addison-Wesley},
	author = {Daigneau, Robert},
	date = {2012},
	note = {{OCLC}: ocn753468449},
	keywords = {Simple Object Access Protocol (Computer network protocol), Web services, Web site development},
}

@inproceedings{reisner_scalable_2017,
	location = {Cham},
	title = {Scalable Conformance Checking of Business Processes},
	isbn = {978-3-319-69462-7},
	doi = {10.1007/978-3-319-69462-7_38},
	series = {Lecture Notes in Computer Science},
	abstract = {Given a process model representing the expected behavior of a business process and an event log recording its actual execution, the problem of business process conformance checking is that of detecting and describing the differences between the process model and the log. A desirable feature is to produce a minimal yet complete set of behavioral differences. Existing conformance checking techniques that achieve these properties do not scale up to real-life process models and logs. This paper presents an approach that addresses this shortcoming by exploiting automata-based techniques. A log is converted into a deterministic automaton in a lossless manner, the input process model is converted into another minimal automaton, and a minimal error-correcting synchronized product of both automata is calculated using an A* heuristic. The resulting automaton is used to extract alignments between traces of the model and traces of the log, or statements describing behavior observed in the log but not captured in the model. An evaluation on synthetic and real-life models and logs shows that the proposed approach outperforms a state-of-the-art method for complete conformance checking.},
	pages = {607--627},
	booktitle = {On the Move to Meaningful Internet Systems. {OTM} 2017 Conferences},
	publisher = {Springer International Publishing},
	author = {Reißner, Daniel and Conforti, Raffaele and Dumas, Marlon and La Rosa, Marcello and Armas-Cervantes, Abel},
	editor = {Panetto, Hervé and Debruyne, Christophe and Gaaloul, Walid and Papazoglou, Mike and Paschke, Adrian and Ardagna, Claudio Agostino and Meersman, Robert},
	date = {2017},
	langid = {english},
	keywords = {Automata, Behavioral alignment, Conformance checking, Process mining},
	file = {Full Text PDF:/Users/ihar/Documents/Zotero/storage/VUJHRMA2/Reißner et al. - 2017 - Scalable Conformance Checking of Business Processe.pdf:application/pdf},
}

% @online{noauthor_c4_nodate,
% 	title = {The C4 model for visualising software architecture},
% 	url = {https://c4model.com/},
% 	urldate = {2023-04-14},
% 	file = {c4-overview.png:/Users/ihar/Documents/Zotero/storage/APIMZTTZ/c4model.com.html:text/html},
% }

@online{noauthor_asgi_nodate,
	title = {{ASGI} (Asynchronous Server Gateway Interface) Specification — {ASGI} 3.0 documentation},
	url = {https://asgi.readthedocs.io/en/latest/specs/main.html},
	urldate = {2023-04-18},
	file = {ASGI (Asynchronous Server Gateway Interface) Specification — ASGI 3.0 documentation:/Users/ihar/Documents/Zotero/storage/MFVYRMGL/main.html:text/html},
    author = {ASGI Team}
}

@misc{van_dongen_bpi_2020_payment,
	title = {{BPI} Challenge 2020: Request For Payment},
	rights = {Creative Commons Attribution Non Commercial 4.0 International},
	url = {https://data.4tu.nl/articles/_/12706886/1},
	shorttitle = {{BPI} Challenge 2020},
	abstract = {This dataset contains the event related to Requests for Payment (should not be travel related): 6,886 cases, 36,796 events. Technically, they should not be linked to travels, but sometimes they can be (this is an unwanted deviation) Parent item: {BPI} Challenge 2020 The dataset contains events pertaining to two years of travel expense claims. In 2017, events were collected for two departments, in 2018 for the entire university. The various permits and declaration documents (domestic and international declarations, pre-paid travel costs and requests for payment) all follow a similar process flow. After submission by the employee, the request is sent for approval to the travel administration. If approved, the request is then forwarded to the budget owner and after that to the supervisor. If the budget owner and supervisor are the same person, then only one of these steps is taken. In some cases, the director also needs to approve the request.The process finished with either the trip taking place or a payment being requested and payed. On a high level, we distinguish two types of trips, namely domestic and international. For domestic trips, no prior permission is needed, i.e. an employee can undertake these trips and ask for reimbursement of the costs afterwards. For international trips, permission is needed from the supervisor. This permission is obtained by filing a travel-permit and this travel permit should be approved before making any arrangements. To get the costs for a travel reimbursed, a claim is filed. This can be done as soon as costs are actually payed (for example for flights or conference registration fees), or within two months after the trip (for example hotel and food costs which are usually payed on the spot).},
	publisher = {4TU.Centre for Research Data},
	author = {van Dongen, Boudewijn},
	editora = {Eindhoven University Of Technology, Department Of Mathematics \{And\} Computer Science},
	editoratype = {collaborator},
	urldate = {2023-04-19},
	date = {2020-03-26},
	langid = {english},
	doi = {10.4121/UUID:895B26FB-6F25-46EB-9E48-0DCA26FCD030},
	doi = {10.4121/UUID:895B26FB-6F25-46EB-9E48-0DCA26FCD030},
	note = {Medium: media types: application/x-gzip, text/plain, text/xml
Version Number: 1
Type: dataset},
	keywords = {{BPI} Challenge, Business Process Intelligence ({BPI}), Collection: {BPI} Challenge 2020, Compliance Checking, {FOS}: Computer and information sciences, {IEEE} Task Force on Process Mining, Information Systems, Process Mining, real life event logs, Time: 2017/2018},
}


@misc{van_dongen_bpi_2020_travel,
	title = {{BPI} Challenge 2020: Prepaid Travel Costs},
	rights = {Creative Commons Attribution Non Commercial 4.0 International},
	url = {https://data.4tu.nl/articles/_/12696722/1},
	shorttitle = {{BPI} Challenge 2020},
	abstract = {This file contains the events related to prepaid travel costs Parent item: {BPI} Challenge 2020 The dataset contains events pertaining to two years of travel expense claims. In 2017, events were collected for two departments, in 2018 for the entire university. The various permits and declaration documents (domestic and international declarations, pre-paid travel costs and requests for payment) all follow a similar process flow. After submission by the employee, the request is sent for approval to the travel administration. If approved, the request is then forwarded to the budget owner and after that to the supervisor. If the budget owner and supervisor are the same person, then only one of these steps is taken. In some cases, the director also needs to approve the request.The process finished with either the trip taking place or a payment being requested and payed. On a high level, we distinguish two types of trips, namely domestic and international. For domestic trips, no prior permission is needed, i.e. an employee can undertake these trips and ask for reimbursement of the costs afterwards. For international trips, permission is needed from the supervisor. This permission is obtained by filing a travel-permit and this travel permit should be approved before making any arrangements. To get the costs for a travel reimbursed, a claim is filed. This can be done as soon as costs are actually payed (for example for flights or conference registration fees), or within two months after the trip (for example hotel and food costs which are usually payed on the spot).},
	publisher = {4TU.Centre for Research Data},
	author = {van Dongen, Boudewijn},
	editora = {Eindhoven University Of Technology, Department Of Mathematics \{And\} Computer Science},
	editoratype = {collaborator},
	urldate = {2023-04-10},
	date = {2020-03-26},
	langid = {english},
	doi = {10.4121/UUID:5D2FE5E1-F91F-4A3B-AD9B-9E4126870165},
	doi = {10.4121/UUID:5D2FE5E1-F91F-4A3B-AD9B-9E4126870165},
	note = {Medium: media types: application/x-gzip, text/plain, text/xml
Version Number: 1
Type: dataset},
	keywords = {Business Process Intelligence ({BPI}), {FOS}: Computer and information sciences, {IEEE} Task Force on Process Mining, Information Systems, real life event logs, {BPI} Challenge, Collection: {BPI} Challenge 2020, Compliance Checking, Process Mining, Time: 2017/2018},
}

@report{weinstock_system_2006,
	title = {On System Scalability},
	rights = {Carnegie Mellon University},
	url = {https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=7887},
	abstract = {This 2006 report presents an analysis of what is meant by scalability and a description of factors to be considered when assessing the potential for system scalability.},
	number = {{CMU}/{SEI}-2006-{TN}-012},
	type = {Technical Note},
	author = {Weinstock, Charles B. and Goodenough, John B.},
	urldate = {2023-04-20},
	date = {2006},
	langid = {english},
	file = {On System Scalability.pdf:/Users/ihar/Documents/Zotero/storage/FK9F6SEB/On System Scalability.pdf:application/pdf},
}

@inproceedings{hu_kubernetes_2021,
	title = {A Kubernetes Autoscaler Based on Pod Replicas Prediction},
	doi = {10.1109/ACCTCS52002.2021.00053},
	abstract = {Kubernetes, as the de facto standard for scheduling and scheduling containers, has been widely used in the industry. However, the existing scaling strategy of Kubernetes is only the response scaling of thresholds. To improve the efficiency of resource scaling, an active Kubernetes auto scaling device based on Pod replica prediction is proposed. The experiment shows that the autoscaler proposed in this paper has the advantage of faster response speed.},
	eventtitle = {2021 Asia-Pacific Conference on Communications Technology and Computer Science ({ACCTCS})},
	pages = {238--241},
	booktitle = {2021 Asia-Pacific Conference on Communications Technology and Computer Science ({ACCTCS})},
	author = {Hu, Tengfei and Wang, Yannian},
	date = {2021-01},
	keywords = {Auto scaling, Container, Heuristic algorithms, Industries, Job shop scheduling, Kubernetes, Prediction algorithms, Predictive models, Smoothing methods, Stability analysis},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/WQHEQVIC/9407757.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/IPVYHI5Z/Hu and Wang - 2021 - A Kubernetes Autoscaler Based on Pod Replicas Pred.pdf:application/pdf},
}

@article{xes_ieee_2016,
	title = {{IEEE} Standard for {eXtensible} Event Stream ({XES}) for Achieving Interoperability in Event Logs and Event Streams},
	doi = {10.1109/IEEESTD.2016.7740858},
	abstract = {A grammar for a tag-based language whose aim is to provide designers of information systems with a unified and extensible methodology for capturing systems behaviors by means of event logs and event streams is defined in the {XES} standard. An {XML} Schema describing the structure of an {XES} event log/stream and a {XML} Schema describing the structure of an extension of such a log/stream are included in this standard. Moreover, a basic collection of so-called {XES} extension prototypes that provide semantics to certain attributes as recorded in the event log/stream is included in this standard.},
	pages = {1--50},
	journaltitle = {{IEEE} Std 1849-2016},
	date = {2016-11},
	note = {Conference Name: {IEEE} Std 1849-2016},
	keywords = {Behavioral sciences, event log, Event recognition, event stream, extensions, Grammar, {IEEE} 1849™, {IEEE} Standards, Information systems, Semantics, system behavior, {XML}},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/L66TZECM/7740858.html:text/html},
}

@report{shafranovich_common_2005,
	title = {Common Format and {MIME} Type for Comma-Separated Values ({CSV}) Files},
	url = {https://datatracker.ietf.org/doc/rfc4180},
	abstract = {This {RFC} documents the format used for Comma-Separated Values ({CSV}) files and registers the associated {MIME} type "text/csv". This memo provides information for the Internet community.},
	number = {{RFC} 4180},
	institution = {Internet Engineering Task Force},
	type = {Request for Comments},
	author = {Shafranovich, Yakov},
	urldate = {2023-04-26},
	date = {2005-10},
	doi = {10.17487/RFC4180},
	note = {Num Pages: 8},
	file = {Full Text PDF:/Users/ihar/Documents/Zotero/storage/FEH3E35K/Shafranovich - 2005 - Common Format and MIME Type for Comma-Separated Va.pdf:application/pdf},
}

@misc{lashkevich_why_2022,
	title = {Why am I Waiting? Data-Driven Analysis of Waiting Times in Business Processes},
	url = {http://arxiv.org/abs/2212.01392},
	doi = {10.48550/arXiv.2212.01392},
	shorttitle = {Why am I Waiting?},
	abstract = {Waiting times in a business process often arise when a case transitions from one activity to another. Accordingly, analyzing the causes of waiting times of activity transitions can help analysts to identify opportunities for reducing the cycle time of a process. This paper proposes a process mining approach to decompose the waiting time observed in each activity transition in a process into multiple direct causes and to analyze the impact of each identified cause on the cycle time efficiency of the process. An empirical evaluation shows that the proposed approach is able to discover different direct causes of waiting times. The applicability of the proposed approach is demonstrated on a real-life process.},
	number = {{arXiv}:2212.01392},
	publisher = {{arXiv}},
	author = {Lashkevich, Katsiaryna and Milani, Fredrik and Chapela-Campa, David and Suvorau, Ihar and Dumas, Marlon},
	urldate = {2023-04-27},
	date = {2022-12-02},
	eprinttype = {arxiv},
	eprint = {2212.01392 [cs]},
	keywords = {Computer Science - Databases, H.4.1},
	file = {arXiv Fulltext PDF:/Users/ihar/Documents/Zotero/storage/A7WXD8L3/Lashkevich et al. - 2022 - Why am I Waiting Data-Driven Analysis of Waiting .pdf:application/pdf;arXiv.org Snapshot:/Users/ihar/Documents/Zotero/storage/9MYAUSVP/2212.html:text/html},
}

@book{van_der_aalst_process_2016,
	location = {Berlin, Heidelberg},
	title = {Process Mining},
	isbn = {978-3-662-49850-7 978-3-662-49851-4},
	url = {http://link.springer.com/10.1007/978-3-662-49851-4},
	publisher = {Springer Berlin Heidelberg},
	author = {Van Der Aalst, Wil},
	urldate = {2023-04-27},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-662-49851-4},
	file = {Van Der Aalst - 2016 - Process Mining.pdf:/Users/ihar/Documents/Zotero/storage/LSE3PSMQ/Van Der Aalst - 2016 - Process Mining.pdf:application/pdf},
}

@incollection{vom_brocke_business_2015,
	location = {Berlin, Heidelberg},
	title = {Business Process Simulation Survival Guide},
	isbn = {978-3-642-45099-0 978-3-642-45100-3},
	url = {https://link.springer.com/10.1007/978-3-642-45100-3_15},
	abstract = {Simulation provides a ﬂexible approach to analyzing business processes. Through simulation experiments various “what if” questions can be answered and redesign alternatives can be compared with respect to key performance indicators. This chapter introduces simulation as an analysis tool for business process management. After describing the characteristics of business simulation models, the phases of a simulation project, the generation of random variables, and the analysis of simulation results, we discuss 15 risks, i.e., potential pitfalls jeopardizing the correctness and value of business process simulation. For example, the behavior of resources is often modeled in a rather na¨ıve manner resulting in unreliable simulation models. Whereas traditional simulation approaches rely on hand-made models, we advocate the use of process mining techniques for creating more reliable simulation models based on real event data. Moreover, simulation can be turned into a powerful tool for operational decision making by using real-time process data.},
	pages = {337--370},
	booktitle = {Handbook on Business Process Management 1},
	publisher = {Springer Berlin Heidelberg},
	author = {Van Der Aalst, Wil M. P.},
	editor = {Vom Brocke, Jan and Rosemann, Michael},
	urldate = {2023-04-27},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-642-45100-3_15},
	file = {Van Der Aalst - 2015 - Business Process Simulation Survival Guide.pdf:/Users/ihar/Documents/Zotero/storage/VJLYM5UF/Van Der Aalst - 2015 - Business Process Simulation Survival Guide.pdf:application/pdf},
}

@inproceedings{lopez-pintado_prosimos_2023,
	location = {Cham},
	title = {Prosimos: Discovering and Simulating Business Processes with Differentiated Resources},
	isbn = {978-3-031-26886-1},
	doi = {10.1007/978-3-031-26886-1_23},
	series = {Lecture Notes in Business Information Processing},
	shorttitle = {Prosimos},
	abstract = {Prosimos is an open-source tool that discovers business process simulation models from execution data (event logs) and that enables users to perform what-if analysis using the resulting models. Prosimos distinguishes itself from other data-driven business process simulation approaches in the way it models resources. Existing data-driven simulation approaches treat resources as undifferentiated entities, grouped into resource pools, and assume that all resources in a pool have the same performance and availability calendars. In contrast, Prosimos allows resources (within a pool) to have different performance and availability profiles. For example, instead of treating all claims officers in an insurance claims handling process as having the same performance and availability, Prosimos may capture scenarios where senior resources perform some tasks faster than junior ones, or scenarios where some resources work part-time. To this end, Prosimos integrates algorithms for discovering differentiated resource profiles from event logs.},
	pages = {346--352},
	booktitle = {Enterprise Design, Operations, and Computing. {EDOC} 2022 Workshops},
	publisher = {Springer International Publishing},
	author = {López-Pintado, Orlenys and Halenok, Iryna and Dumas, Marlon},
	editor = {Sales, Tiago Prince and Proper, Henderik A. and Guizzardi, Giancarlo and Montali, Marco and Maggi, Fabrizio Maria and Fonseca, Claudenir M.},
	date = {2023},
	langid = {english},
	file = {Full Text PDF:/Users/ihar/Documents/Zotero/storage/RTAHGHTI/López-Pintado et al. - 2023 - Prosimos Discovering and Simulating Business Proc.pdf:application/pdf},
}

@article{linthicum_practical_2016,
	title = {Practical Use of Microservices in Moving Workloads to the Cloud},
	volume = {3},
	issn = {2325-6095},
	doi = {10.1109/MCC.2016.114},
	abstract = {Most enterprises believe the cloud will become the new home for applications; however, not all applications are ready for the cloud. Containers and microservices make it easier to move applications to the cloud. The application developer charged with refactoring the application must think about how to best redesign the applications to become containerized and service oriented. In essence, you're turning a monolithic application into something that's more complex and distributed. However, the real objective is for it to become more productive, agile, and cost effective.},
	pages = {6--9},
	number = {5},
	journaltitle = {{IEEE} Cloud Computing},
	author = {Linthicum, David S.},
	date = {2016-09},
	note = {Conference Name: {IEEE} Cloud Computing},
	keywords = {cloud computing, Cloud computing, Cloud Tidbits, Complexity theory, Computer architecture, Computer security, containers, Information management, Information storage, microservices, service-oriented architecture, Service-oriented architecture},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/HKJR42TP/7742277.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/4KN7CESL/Linthicum - 2016 - Practical Use of Microservices in Moving Workloads.pdf:application/pdf},
}

@article{sill_design_2016,
	title = {The Design and Architecture of Microservices},
	volume = {3},
	issn = {2325-6095},
	doi = {10.1109/MCC.2016.111},
	abstract = {Microservices are sweeping through cloud design architectures, at once embodying new trends and making use of previous paradigms. This column explores the basis for these trends in both modern and historical standards, and sets out a direction for the future of microservices development.},
	pages = {76--80},
	number = {5},
	journaltitle = {{IEEE} Cloud Computing},
	author = {Sill, Alan},
	date = {2016-09},
	note = {Conference Name: {IEEE} Cloud Computing},
	keywords = {architecture, automation, cloud, Cloud computing, Computer architecture, containers, data, design, Design methdology, microservices, networks, Service computing, standards, Standards development, Storage automation},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/NNY93D3E/7742259.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/VZAU5JJE/Sill - 2016 - The Design and Architecture of Microservices.pdf:application/pdf},
}

@incollection{puliafito_container_2019,
	location = {Cham},
	title = {Container Orchestration: A Survey},
	isbn = {978-3-319-92377-2 978-3-319-92378-9},
	url = {http://link.springer.com/10.1007/978-3-319-92378-9_14},
	shorttitle = {Container Orchestration},
	pages = {221--235},
	booktitle = {Systems Modeling: Methodologies and Tools},
	publisher = {Springer International Publishing},
	author = {Casalicchio, Emiliano},
	editor = {Puliafito, Antonio and Trivedi, Kishor S.},
	urldate = {2023-04-28},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-319-92378-9_14},
	note = {Series Title: {EAI}/Springer Innovations in Communication and Computing},
	file = {Casalicchio - 2019 - Container Orchestration A Survey.pdf:/Users/ihar/Documents/Zotero/storage/BDUS44BK/Casalicchio - 2019 - Container Orchestration A Survey.pdf:application/pdf},
}

@inproceedings{weets_limitations_2015,
	title = {Limitations and challenges of {HDFS} and {MapReduce}},
	doi = {10.1109/ICGCIoT.2015.7380524},
	abstract = {Over these past 6 years, Hadoop has become a highly popular solution to store and process a large amount of data for analysis purpose. Those 6 years of utilization along with the researches undergone which focused on Hadoop enable researches to have a good overview of its advantages, drawbacks and limitations in order to improve the solution initiated introduced. Even though Hadoop 2.0 released in 2012 brought several improvements, especially regarding Hadoop Distributed File System ({HDFS}) availability and the cluster resource management during {MapReduce} job execution through the {YARN} architecture, numerous scopes of improvements are yet to be explored. This paper aims to present those drawbacks and limitations of Hadoop 1.0, explain what brings Hadoop 2.0 and what these remaining scopes of improvements for Hadoop are.},
	eventtitle = {2015 International Conference on Green Computing and Internet of Things ({ICGCIoT})},
	pages = {545--549},
	booktitle = {2015 International Conference on Green Computing and Internet of Things ({ICGCIoT})},
	author = {Weets, Jean-François and Kakhani, Manish Kumar and Kumar, Anil},
	date = {2015-10},
	keywords = {Computer languages, Hadoop, {HDFS}, {MapReduce}, Memory management, Metadata, Resource management, Scalability, Security, Yarn},
	file = {IEEE Xplore Abstract Record:/Users/ihar/Documents/Zotero/storage/V43N2SXR/7380524.html:text/html;IEEE Xplore Full Text PDF:/Users/ihar/Documents/Zotero/storage/C453V77B/Weets et al. - 2015 - Limitations and challenges of HDFS and MapReduce.pdf:application/pdf},
}

@article{telea_visual_2011,
	title = {Visual software analytics for the build optimization of large-scale software systems},
	volume = {26},
	issn = {0943-4062, 1613-9658},
	url = {http://link.springer.com/10.1007/s00180-011-0248-2},
	doi = {10.1007/s00180-011-0248-2},
	abstract = {Visual analytics is the science of analytical reasoning facilitated by interactive visual interfaces. In this paper, we present an adaptation of the visual analytics framework to the context of software understanding for maintenance. We discuss the similarities and differences of the general visual analytics context with the software maintenance context, and present in detail an instance of a visual software analytics application for the build optimization of large-scale code bases. Our application combines and adapts several data mining and information visualization techniques in answering several questions that help developers in assessing and reducing the build cost of such code bases by means of user-driven, interactive analysis techniques.},
	pages = {635--654},
	number = {4},
	journaltitle = {Computational Statistics},
	shortjournal = {Comput Stat},
	author = {Telea, Alexandru and Voinea, Lucian},
	urldate = {2023-04-30},
	date = {2011-12},
	langid = {english},
	file = {Telea and Voinea - 2011 - Visual software analytics for the build optimizati.pdf:/Users/ihar/Documents/Zotero/storage/56DDPDZ7/Telea and Voinea - 2011 - Visual software analytics for the build optimizati.pdf:application/pdf},
}

@inproceedings{DBLP:conf/icpm/Chapela-CampaD22,
  author    = {David Chapela{-}Campa and
               Marlon Dumas},
  editor    = {Andrea Burattin and
               Artem Polyvyanyy and
               Barbara Weber},
  title     = {Modeling Extraneous Activity Delays in Business Process Simulation},
  booktitle = {Proceedings of the 4th International Conference on Process Mining ({ICPM} 2022)},
  pages     = {72--79},
  publisher = {{IEEE}},
  year      = {2022},
  url       = {https://doi.org/10.1109/ICPM57379.2022.9980544},
  doi       = {10.1109/ICPM57379.2022.9980544},
  timestamp = {Tue, 03 Jan 2023 07:35:57 +0100},
  biburl    = {https://dblp.org/rec/conf/icpm/Chapela-CampaD22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{DBLP:journals/corr/abs-2303-17463,
  author    = {David Chapela{-}Campa and
               Ismail Benchekroun and
               Opher Baron and
               Marlon Dumas and 
               Dmitry Krass and
               Arik Senderovich},
  title     = {Can I Trust My Simulation Model? Measuring the Quality of Business Process Simulation Models},
  journal   = {CoRR},
  volume    = {abs/2303.17463},
  year      = {2023},
  url       = {https://doi.org/10.48550/arXiv.2303.17463},
  doi       = {10.48550/arXiv.2303.17463},
  eprinttype = {arXiv},
  eprint    = {2303.17463},
  timestamp = {Thu, 30 Mar 2023 15:40:26 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2206-14051.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/dke/Estrada-TorresC21,
  author       = {Bedilia Estrada{-}Torres and
                  Manuel Camargo and
                  Marlon Dumas and
                  Luciano Garc{\'{\i}}a{-}Ba{\~{n}}uelos and
                  Ibrahim Mahdy and
                  Maksym Yerokhin},
  title        = {Discovering business process simulation models in the presence of
                  multitasking and availability constraints},
  journal      = {Data Knowl. Eng.},
  volume       = {134},
  pages        = {101897},
  year         = {2021},
  url          = {https://doi.org/10.1016/j.datak.2021.101897},
  doi          = {10.1016/j.datak.2021.101897},
  timestamp    = {Wed, 07 Dec 2022 23:04:30 +0100},
  biburl       = {https://dblp.org/rec/journals/dke/Estrada-TorresC21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{verma_large-scale_2015,
	location = {Bordeaux France},
	title = {Large-scale cluster management at Google with Borg},
	isbn = {978-1-4503-3238-5},
	url = {https://dl.acm.org/doi/10.1145/2741948.2741964},
	doi = {10.1145/2741948.2741964},
	abstract = {Google’s Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines.},
	eventtitle = {{EuroSys} '15: Tenth {EuroSys} Conference 2015},
	pages = {1--17},
	booktitle = {Proceedings of the Tenth European Conference on Computer Systems},
	publisher = {{ACM}},
	author = {Verma, Abhishek and Pedrosa, Luis and Korupolu, Madhukar and Oppenheimer, David and Tune, Eric and Wilkes, John},
	urldate = {2023-05-08},
	date = {2015-04-17},
	langid = {english},
	file = {Verma et al. - 2015 - Large-scale cluster management at Google with Borg.pdf:/Users/ihar/Documents/Zotero/storage/SUH4DJWF/Verma et al. - 2015 - Large-scale cluster management at Google with Borg.pdf:application/pdf},
}

@article{burns_borg_2016,
	title = {Borg, Omega, and Kubernetes: Lessons learned from three container-management systems over a decade},
	volume = {14},
	issn = {1542-7730, 1542-7749},
	url = {https://dl.acm.org/doi/10.1145/2898442.2898444},
	doi = {10.1145/2898442.2898444},
	shorttitle = {Borg, Omega, and Kubernetes},
	abstract = {Though widespread interest in software containers is a relatively recent phenomenon, at Google we have been managing Linux containers at scale for more than ten years and built three different container-management systems in that time. Each system was heavily influenced by its predecessors, even though they were developed for different reasons. This article describes the lessons we’ve learned from developing and operating them.},
	pages = {70--93},
	number = {1},
	journaltitle = {Queue},
	shortjournal = {Queue},
	author = {Burns, Brendan and Grant, Brian and Oppenheimer, David and Brewer, Eric and Wilkes, John},
	urldate = {2023-04-28},
	date = {2016-01},
	langid = {english},
	file = {Full Text PDF:/Users/ihar/Documents/Zotero/storage/IXUN8G7Y/Burns et al. - 2016 - Borg, Omega, and Kubernetes Lessons learned from .pdf:application/pdf},
}
